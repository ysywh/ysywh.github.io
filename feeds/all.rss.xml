<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>YsY记录点滴</title><link>http://ysywh.github.io/</link><description></description><atom:link href="http://ysywh.github.io/feeds/all.rss.xml" rel="self"></atom:link><lastBuildDate>Thu, 01 Oct 2015 17:30:00 +0800</lastBuildDate><item><title>数据结构</title><link>http://ysywh.github.io/pages/2015/06/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html</link><description>&lt;p&gt;2015-6-1 by ysy   &lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;程序=数据结构+算法，而数据结构是什么，都有哪些数据结构，如何把它应用于代码实践中，自己其实也是模糊不清的。虽然说从大学学写代码到现在，也接触过很多种数据结构，但也没有系统的总结和思考过，甚至复写一遍都困难。因此决定下来这段时间，好好地学习回顾一下一些基本的数据结构，包括一些最近本的算法，当做记录和加强基本功吧。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;数据结构&lt;/strong&gt;：一组有特定数据关系的数据元素集合。根据数据关系，因此衍生出以下四种基本类型的数据结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;集合结构 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;线性结构    &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;树形结构&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图结构&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;集合结构就像数学中的集合，很好理解；线性结构就是数据中一对一关系；树形结构就是数据是一对多关系；图结构就是多对多关系。虽然这样描述不准确，但好理解就OK。&lt;/p&gt;
&lt;p&gt;说到数据结构，让我想起 &lt;strong&gt;数据类型&lt;/strong&gt;，简单的认为，数据类型是带有操作的值的总称，是操作的对象。数据类型有基本数据类型和非基本数据类型，如在C语言中，基本数据类型如int类型，其操作可以有加减乘除等操作，非基本数据类型，可以是数据结构和定义的操作，如顺序表（线性结构）和一些插入删除的操作，其实在C++中，类也算是一种高级的数据类型，因为含有数据成员和成员函数。&lt;/p&gt;
&lt;p&gt;说完数据类型，再来看数据结构，每种数据结构都可以有一些相应的操作，比如插入、删除或查找数据等，好吧，数据结构加上操作就是可以使用的数据类型了。而插入对于不同的数据类型，甚至同一种数据结构，相同操作的机理也是不同的。比如对于链式存储的线性表（链表）和顺序存储的线性表（顺序表）对于查找操作的机理也是不一样的，即用不同方法查找（二分查找、Fbonacci查找）的效率不同，这就牵扯到&lt;strong&gt;算法&lt;/strong&gt;了。当然，除了数据结构操作的方法，包括一些其他问题解决办法，比如排序方法（冒泡排序、插入排序），都是有具体的算法的。算法的优劣，需要根据具体情况采用具体的解决办法，这才是最优的。&lt;/p&gt;
&lt;p&gt;刚才数据结构中提到的数据关系，其实是一种逻辑关系，真正在计算机中存储不同数据结构，都会有两种物理关系，顺序存储和链式存储。必定这种物理关系需要反应在语言上，顺序存储则对应数据类型中的一维数组，链式存储则是一系列指针类型。因此，实现不同数据结构都可以使用顺序存储和链式存储，则数据结构和采用实现的存储结构无直接关系。比如，对于线性结构的线性表，可以是顺序存储实现，称为顺序表，也可以是链式存储实现，称为链式表。&lt;/p&gt;
&lt;p&gt;当然，用不同存储方法实现数据结构后，对数据结构进行操作是有差异的。顺序存储最大的特点就是利于查找，即通过数组下标就可以快速完成，但是插入或是删除数据需要移动其他元素，复杂度O(n)；但是对于链式存储，插入和删除非常便利，因为是指针直接操作目标元素，不需要操作其他元素，但是对于查找等操作，却需要逐一遍历到目标元素才可以，不如顺序存储。虽然各有优劣，还是老话，需要根据实际情况选择合适的实现方式。&lt;/p&gt;
&lt;p&gt;一口气理清了数据结构、数据类型等概念，当做基础吧。为了更好理解和分析数据结构，后期一些基本数据结构估计大多数用C语言实现，可能一些算法，比如查找或是排序，重点在于方法和实现，就用Python等语言，便于实现。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">ysy</dc:creator><pubDate>Sun, 30 Aug 2015 17:30:00 +0800</pubDate><guid>tag:ysywh.github.io,2015-06-01:pages/2015/06/01/数据结构.html</guid><category>数据结构，算法</category></item><item><title>OVS源码分析----OpenFlow消息处理</title><link>http://ysywh.github.io/pages/2015/05/02/OVS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%E2%80%94%E2%80%94OpenFlow%E6%B6%88%E6%81%AF%E5%A4%84%E7%90%86.html</link><description>&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;OVS作为交换机，可以通过安全通道与控制器进行消息交互。控制器向OVS下发Openflow消息，可以完成对数据层面策略下发，流控制等功能。OVS接收到控制器下发的Openflow消息，需要对其进行接收，解析与处理，如安装流表项等操作。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;下文按照OVS接收处理openflow消息的处理流程进行分析：&lt;/p&gt;
&lt;p&gt;handle_openflow(ofproto\ofproto.c)开始对openflow消息进行具体处理，因此这个函数开始进行分析。首先说明一个重要数据结构。&lt;/p&gt;
&lt;p&gt;数据结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ofconn(ofproto\connmgr.c)：代表ovs和控制器之间的一次openflow连接。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;主要的成员&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;connmgr（连接管理器）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rconn（一次可靠地openflow连接）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;1 static bool  handle_openflow(struct ofconn &lt;em&gt;ofconn, struct ofpbuf &lt;/em&gt;ofp_msg)&lt;/h4&gt;
&lt;p&gt;接收控制器下发的openflow消息，并且调用函数handle_openflow__进行消息类别判断，做出对应的处理。若接收到错误的openflow消息则会返回error，向控制器发“error消息”进行回复。&lt;/p&gt;
&lt;h4&gt;2 satic enum ofperr handle_openflow__(struct ofconn &lt;em&gt;ofconn, const struct ofpbuf &lt;/em&gt;msg)&lt;/h4&gt;
&lt;p&gt;数据结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ofp_header：openflow消息packets头部。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据成员&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;version（openflow消息版本号）&lt;/li&gt;
&lt;li&gt;type（openflow消息类型）&lt;/li&gt;
&lt;li&gt;length(openflow消息长度)&lt;/li&gt;
&lt;li&gt;xid（每次openflow消息id号，回复使用相同xid）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;先从接收到的消息msg中提取出openflow消息头部msg-&amp;gt;data，赋值给oh。oh利用函数ofptype_decode获得openflow消息类型type（枚举型ofptype中罗列了各种消息类型，lib\ofp-msgs.h）。通过判别type找到与消息类型相符的具体消息处理函数，从而进行消息处理。比如下面详细分析一下flowmod消息。&lt;/p&gt;
&lt;h4&gt;3 static enum ofperr handle_flow_mod(struct ofconn &lt;em&gt;ofconn, const struct ofp_header &lt;/em&gt;oh)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;数据结构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ofputil_flow_mod（lib\ofp-util.h）：flowmod消息的数据结构&lt;ul&gt;
&lt;li&gt;数据成员&lt;ul&gt;
&lt;li&gt;match: 匹配域定义和掩码定义（match有两个成员flow（定义了可以匹配的各个字段）和flow_wildcards（bit掩码）)&lt;/li&gt;
&lt;li&gt;priority，cookie，command，buffer_id,out_port和&lt;/li&gt;
&lt;li&gt;ofpact：ofpact是action的头部，含有type等成员&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过函数ofpbuf_use_stub给ofpacts分配一块缓存opfbuf，然后通过调用函数ofputil_decode_flow_mod得到数据结构ofputil_flow_mod实体fm和实体ofpacts，则此时fm即包含flowmod消息格式的各个字段内容，而ofpacts缓存中含有action，并其中fm中的成员ofpacts指向这个缓存ofpacts。最后调用函数handle_flow_mod__，函数中，根据flowmod消息fm的command类型不同（五种），选择command相应流表项处理函数，在用户空间插入、修改或是删除流表项。&lt;/p&gt;
&lt;h4&gt;4 static enum ofperr add_flow(struct ofproto &lt;em&gt;ofproto, struct ofconn &lt;/em&gt;ofconn,const struct ofputil_flow_mod &lt;em&gt;fm, const struct ofp_header &lt;/em&gt;request)&lt;/h4&gt;
&lt;p&gt;选择flowmod指定id的表，根据flowmod消息创建分类流规则rule，并且插入rule，等再有相同流过来进行匹配，从而创建流表项。具体如下：&lt;/p&gt;
&lt;p&gt;先通过fm-&amp;gt;table_id获得flowmod指定id的流表，如果id号大于指定的最大流表数则会返回相应error类型。找到table id后，根据函数rule_alloc()分配一个分类器rule，随后调用函数cls_rule_init(&amp;amp;rule-&amp;gt;cr, &amp;amp;fm-&amp;gt;match, fm-&amp;gt;priority)填充rule-&amp;gt;cr，则rule的匹配域和优先级字段基本填充完成。之后进行冲突检测（check for overlap），防止重复添加相同rule。之后对rule各个字段进行填充，调用函数oftable_replace_rule插入这个初始化好的rule。&lt;/p&gt;
&lt;p&gt;这样addflow任务基本完成，等待以后相同流在核心层匹配失败后，upcall到用户层，则会根据匹配这个rule进行流表项的建立工作，如果不存在匹配的rule，则会丢弃或是上交controller，具体见用户态处理upcall消息分析。至于modify和delete类型flowmod消息，基本分析相同，如对command为modify的flowmod消息，则修改指定rule的action。&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">ysy</dc:creator><pubDate>Sun, 30 Aug 2015 17:30:00 +0800</pubDate><guid>tag:ysywh.github.io,2015-05-02:pages/2015/05/02/OVS源码分析————OpenFlow消息处理.html</guid><category>OVS souce code</category></item><item><title>Cbench测试Opendaylight性能</title><link>http://ysywh.github.io/pages/2015/04/03/Cbench%E6%B5%8B%E8%AF%95Opendaylight%E6%80%A7%E8%83%BD.html</link><description>&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;要求和目标：用Cbench测试Opendaylight控制器的吞吐量和延时性能，拓扑简单设定为四个交换机&lt;/p&gt;
&lt;p&gt;实验通过Cbench模拟出拓扑，并对Opendaylight进行测试。&lt;/p&gt;
&lt;h3&gt;一：测试平台：&lt;/h3&gt;
&lt;p&gt;由于测试结果和测试平台的性能紧密联系，因此记录下测试平台参数。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;硬件参数：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CPU: Intel(R) Xeon(R) CPU E5-2609 0 @ 2.40GHz&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Memory: 8GB DDR3 - 1600 Mhz&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;软件参数:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OS: Ubuntu 14.04&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Java: OpenJDK java version "1.7.0"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Opendaylight版本:Helium-SR2&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Opendaylight设置为初始默认值&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;二：测试步骤&lt;/h3&gt;
&lt;p&gt;准备工作：先安装好&lt;a href="https://www.opendaylight.org/downloads"&gt;OpenDaylight&lt;/a&gt;和&lt;a href="https://github.com/deepurple/cbench-src"&gt;Cbench&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;1 开启opendaylight:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench1.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 安装Opendaylight控制器测试组件：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench2.png" /&gt;&lt;/p&gt;
&lt;p&gt;说明：Opendaylight不同于其他控制器，需要测试组件的支持，且测试组件具有两种测试模式：RPC和data store模式（区别见最后说明），以下分别用Cbench进行吞吐量和延时的测试.&lt;/p&gt;
&lt;h3&gt;RPC模式性能测试&lt;/h3&gt;
&lt;p&gt;首先，在RPC模式下进行Opendaylight性能测试：&lt;/p&gt;
&lt;p&gt;1 在opendaylight中开启RPC模式的测试组件：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench3.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 开启Cbench，测试控制器吞吐量(throughput)性能:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench4.png" /&gt;&lt;/p&gt;
&lt;p&gt;这里简单说明一下参数意义，s是交换机数量，M是每个交换机连接的主机数量，m是每次测试周期，l是测试循环次数，-t是进行吞吐量throughput测试，没有t则是延时latency测试。后面测试命令不再赘述。&lt;/p&gt;
&lt;p&gt;吞吐量测试结果截图：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench5.png" /&gt;&lt;/p&gt;
&lt;p&gt;测试结果简单解释：截图第二行显示测试性能的方面，可以看到是throughout，则是吞吐量测试。测试结果有10行数据，每行代表一次测试，每行有4个结果，单位是秒，代表每个交换机的测试结果，最后会有每毫秒的结果。最后一行是测试总的结果。&lt;/p&gt;
&lt;p&gt;3 开启Cbench，测试控制器延时（latency）性能：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench6.png" /&gt;&lt;/p&gt;
&lt;p&gt;测试结果截图：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench7.png" /&gt;&lt;/p&gt;
&lt;p&gt;特别说明：延迟测试结果要对测试的结果取倒数才是延迟。&lt;/p&gt;
&lt;h3&gt;data store模式性能测试&lt;/h3&gt;
&lt;p&gt;其次，在data store模式下进行Opendaylight性能测试:&lt;/p&gt;
&lt;p&gt;1关闭RPC模式，开启data store模式的测试组件：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench8.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 开启Cbench，测试控制器吞吐量(throughput)性能:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench9.png" /&gt;&lt;/p&gt;
&lt;p&gt;吞吐量测试结果截图：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench10.png" /&gt;&lt;/p&gt;
&lt;p&gt;3 开启Cbench，测试控制器延时（latency）性能：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench11.png" /&gt;&lt;/p&gt;
&lt;p&gt;延迟测试结果截图：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench12.png" /&gt; &lt;/p&gt;
&lt;h3&gt;说明&lt;/h3&gt;
&lt;p&gt;1 两种模式特别说明，来自Opendaylight官网：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;RPC : programming flows directly through an RPC to the OF Plugin&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;data store : programming flows by writing them into the MD-SAL config space, from where they are picked up by the FRM and programmed into the plugin)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2 参数命令和结果截图说明见4和5，之后的不再赘述。&lt;/p&gt;
&lt;p&gt;3 测试结果的文本数据，见附件result.txt&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">ysy</dc:creator><pubDate>Sun, 30 Aug 2015 17:30:00 +0800</pubDate><guid>tag:ysywh.github.io,2015-04-03:pages/2015/04/03/Cbench测试Opendaylight性能.html</guid><category>Cbench OpenDaylight</category></item><item><title>Docker搭建Hadoop集群环境和Wordcount实验</title><link>http://ysywh.github.io/pages/2015/03/11/Docker%E6%90%AD%E5%BB%BAHadoop%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%92%8CWordcount%E5%AE%9E%E9%AA%8C.html</link><description>&lt;p&gt;2015-3-8 by ysy   &lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;利用docker搭建Hadoop环境，并且完成Mapreduce中Word count实验  &lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;一：实验目标&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;学习docker基本命令&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;搭建只有一个master和两个slave的Hadoop集群环境&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;进行wordcount实验,理解mapreduce和hdfs等工作机制&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;二：docker基本命令&lt;/h4&gt;
&lt;p&gt;docket是目前较为流行的虚拟化技术，可以方便轻松的在Linux中建立容器，达到虚拟化需求。&lt;/p&gt;
&lt;p&gt;基本操作命令如下，更多参考&lt;a href="!http://dockerpool.com/static/books/docker_practice/index.html"&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;启动容器：&lt;code&gt;docker run 镜像名&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;暂停容器：&lt;code&gt;docker stop 容器名&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重启开启容器：&lt;code&gt;docker start 容器名&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;进入容器：&lt;code&gt;docker attach 容器名&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;三：Hadoop集群环境搭建&lt;/h4&gt;
&lt;p&gt;1 Hadoop集群分为一个master和两个slave，因此依次用docker开启相应容器,其中需要做端口映射：&lt;/p&gt;
&lt;p&gt;&lt;img alt="1" src="http://gitlab.local/uploads/course/course_hadoop/955c4756f3/1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="2" src="http://gitlab.local/uploads/course/course_hadoop/7ce0511f3b/2.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="3" src="http://gitlab.local/uploads/course/course_hadoop/3ef073ba31/3.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 利用命令编辑： &lt;code&gt;vi /etc/hosts&lt;/code&gt;,加入master和两个slave的容器号和ip。之后需要 &lt;strong&gt;开启sshd服务&lt;/strong&gt; ，使其生效：' service  sshd start '&lt;/p&gt;
&lt;p&gt;&lt;img alt="4" src="http://gitlab.local/uploads/course/course_hadoop/d29157c596/4.png" /&gt;&lt;/p&gt;
&lt;p&gt;3 分别登陆master和slave，利用命令chkconfig命令查看服务&lt;/p&gt;
&lt;p&gt;&lt;img alt="5" src="http://gitlab.local/uploads/course/course_hadoop/83312aa0f6/5.png" /&gt;&lt;/p&gt;
&lt;p&gt;4 master上开启相应服务：&lt;/p&gt;
&lt;p&gt;开启Hadoop服务：service hadoop-hdfs-namenode start&lt;/p&gt;
&lt;p&gt;开启mapreduce服务：service hadoop-yarn-resourcemanager start&lt;/p&gt;
&lt;p&gt;开启任务记录的服务：service hadoop-mapreduce-historyserver start&lt;/p&gt;
&lt;p&gt;&lt;img alt="6" src="http://gitlab.local/uploads/course/course_hadoop/6e2e318e55/6.png" /&gt;&lt;/p&gt;
&lt;p&gt;5 在两个slave上分别开启Hadoop服务和mapreduce服务：&lt;/p&gt;
&lt;p&gt;service hadoop-hdfs-datanode start&lt;/p&gt;
&lt;p&gt;service hadoop-yarn-nodemanager start&lt;/p&gt;
&lt;p&gt;&lt;img alt="7" src="http://gitlab.local/uploads/course/course_hadoop/3a2cf8df6a/70.png" /&gt;&lt;/p&gt;
&lt;p&gt;6 三项服务分别可以在web端验证服务是否正确打开。至此，hadoop集群环境搭建完毕&lt;/p&gt;
&lt;p&gt;192.168.59.103:50070&lt;/p&gt;
&lt;p&gt;192.168.59.103:8088&lt;/p&gt;
&lt;p&gt;192.168.59.103:19888&lt;/p&gt;
&lt;p&gt;&lt;img alt="8" src="http://gitlab.local/uploads/course/course_hadoop/2ff2b313c1/8.png" /&gt;&lt;/p&gt;
&lt;h4&gt;三：Word count实验&lt;/h4&gt;
&lt;p&gt;word count 实验就是利用Mapreduce框架，对文本中的单词进行数量统计。&lt;/p&gt;
&lt;p&gt;1 建立一个text文件，写入内容，并put入hdfs文件系统后命名为wordcount.input文件，并查看其内容：&lt;/p&gt;
&lt;p&gt;&lt;img alt="9" src="http://gitlab.local/uploads/course/course_hadoop/47c3b12887/7.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 利用Wordcount脚本进行单词计数的简单实验,经过map和reduce等操作把经过输出到Wordcount.output中:&lt;/p&gt;
&lt;p&gt;&lt;img alt="10" src="http://gitlab.local/uploads/course/course_hadoop/f93f01d942/9.png" /&gt;&lt;/p&gt;
&lt;p&gt;3 登陆web可以观察任务状态，在输出文件中查看Wordcount结果，和预想结果相同，试验成功：&lt;/p&gt;
&lt;p&gt;&lt;img alt="11" src="http://gitlab.local/uploads/course/course_hadoop/7bd9c88362/8.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="12" src="http://gitlab.local/uploads/course/course_hadoop/bccbdf2a9e/10.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="13" src="http://gitlab.local/uploads/course/course_hadoop/9b7e274748/11.png" /&gt;&lt;/p&gt;
&lt;h4&gt;四：心得&lt;/h4&gt;
&lt;p&gt;1 对hdfs文件系统有了基本了解，利用简单的Wordcount实验对map和reduce有了直观认识，深觉此技术的有用性&lt;/p&gt;
&lt;p&gt;2 虽然完成本次试验，但是简单的实验还不能对Hadoop有更深刻的学习，希望今后学习其架构及其源码，多做实验达到学习的目的&lt;/p&gt;
&lt;p&gt;3 最后简单记录一下遇到的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每次开启容器后，ip可能会发生变化，要记得修改hosts文件，否则会出现 &lt;code&gt;Hadoop fs shell&lt;/code&gt; 无法操作的问题&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其次，需要关闭安全模式，这样才可以向hdfs文件系统中put内容等操作 &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">ysy</dc:creator><pubDate>Wed, 19 Aug 2015 17:30:00 +0800</pubDate><guid>tag:ysywh.github.io,2015-03-11:pages/2015/03/11/Docker搭建Hadoop集群环境和Wordcount实验.html</guid><category>mapreduce</category><category>word count</category></item><item><title>MapReduce之letter count</title><link>http://ysywh.github.io/pages/2015/03/02/MapReduce%E4%B9%8Bletter%20count.html</link><description>&lt;p&gt;2015-3-2 by ysy  &lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;本节在安装好的Eclipse环境中，尝试使用 MapReduce编程环境，运行letter count代码进行学习验证。letter count 实验就是对一段英文中出现的每个字母进行数量统计，比较基础的练习。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;1 创建新的工程lettercount,并且加载需要的Hadoop库：&lt;/p&gt;
&lt;p&gt;&lt;img alt="1" src="http://gitlab.local/uploads/course/course_hadoop/bf8af6a841/1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="2" src="http://gitlab.local/uploads/course/course_hadoop/3e50a19c6b/2.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="3" src="http://gitlab.local/uploads/course/course_hadoop/b465f66e7d/3.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 在网上寻找一个mapreduce的Wordcount代码文件，在map类中添加计算letter的代码，并且注释掉计算word的代码，加上对每个字母进行统计的代码，map输出键值对为（字母，one)，在reduce中进行合计，于统计word思路相同：&lt;/p&gt;
&lt;p&gt;&lt;img alt="5" src="http://gitlab.local/uploads/course/course_hadoop/acaaa07b4e/5.png" /&gt;&lt;/p&gt;
&lt;p&gt;3 运行前添加输入和输入文件，输入文件内容是一段英文，经过mapreduce运行计算后会把letter计算结果输出到输出文件中：&lt;/p&gt;
&lt;p&gt;&lt;img alt="4" src="http://gitlab.localuploads/course/course_hadoop/84a81d19fc/4.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="6" src="http://gitlab.local/uploads/course/course_hadoop/9754fce9ef/6.png" /&gt;&lt;/p&gt;
&lt;p&gt;4 通过export输出jar包，然后导入带有Hadoop的Linux系统中，进行实际运行计算：&lt;/p&gt;
&lt;p&gt;&lt;img alt="7" src="http://gitlab.local/uploads/course/course_hadoop/a1c5c158d1/7.png" /&gt;&lt;/p&gt;
&lt;p&gt;5 可以通过对比输入文件内容，比较计算的输出的结果，输出文件为两个：&lt;/p&gt;
&lt;p&gt;&lt;img alt="8" src="http://gitlab.local/uploads/course/course_hadoop/f70bf9a61c/8.png" /&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">ysy</dc:creator><pubDate>Thu, 01 Oct 2015 17:30:00 +0800</pubDate><guid>tag:ysywh.github.io,2015-03-02:pages/2015/03/02/MapReduce之letter count.html</guid><category>mapreduce</category><category>letter count</category></item></channel></rss>