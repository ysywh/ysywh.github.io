<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>YsY记录点滴</title><link href="http://ysywh.github.io/" rel="alternate"></link><link href="http://ysywh.github.io/feeds/all-zh.atom.xml" rel="self"></link><id>http://ysywh.github.io/</id><updated>2015-10-01T17:30:00+08:00</updated><entry><title>数据结构</title><link href="http://ysywh.github.io/pages/2015/06/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html" rel="alternate"></link><updated>2015-08-30T17:30:00+08:00</updated><author><name>ysy</name></author><id>tag:ysywh.github.io,2015-06-01:pages/2015/06/01/数据结构.html</id><summary type="html">&lt;p&gt;2015-6-1 by ysy   &lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;程序=数据结构+算法，而数据结构是什么，都有哪些数据结构，如何把它应用于代码实践中，自己其实也是模糊不清的。虽然说从大学学写代码到现在，也接触过很多种数据结构，但也没有系统的总结和思考过，甚至复写一遍都困难。因此决定下来这段时间，好好地学习回顾一下一些基本的数据结构，包括一些最近本的算法，当做记录和加强基本功吧。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;strong&gt;数据结构&lt;/strong&gt;：一组有特定数据关系的数据元素集合。根据数据关系，因此衍生出以下四种基本类型的数据结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;集合结构 &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;线性结构    &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;树形结构&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;图结构&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;集合结构就像数学中的集合，很好理解；线性结构就是数据中一对一关系；树形结构就是数据是一对多关系；图结构就是多对多关系。虽然这样描述不准确，但好理解就OK。&lt;/p&gt;
&lt;p&gt;说到数据结构，让我想起 &lt;strong&gt;数据类型&lt;/strong&gt;，简单的认为，数据类型是带有操作的值的总称，是操作的对象。数据类型有基本数据类型和非基本数据类型，如在C语言中，基本数据类型如int类型，其操作可以有加减乘除等操作，非基本数据类型，可以是数据结构和定义的操作，如顺序表（线性结构）和一些插入删除的操作，其实在C++中，类也算是一种高级的数据类型，因为含有数据成员和成员函数。&lt;/p&gt;
&lt;p&gt;说完数据类型，再来看数据结构，每种数据结构都可以有一些相应的操作，比如插入、删除或查找数据等，好吧，数据结构加上操作就是可以使用的数据类型了。而插入对于不同的数据类型，甚至同一种数据结构，相同操作的机理也是不同的。比如对于链式存储的线性表（链表）和顺序存储的线性表（顺序表）对于查找操作的机理也是不一样的，即用不同方法查找（二分查找、Fbonacci查找）的效率不同，这就牵扯到&lt;strong&gt;算法&lt;/strong&gt;了。当然，除了数据结构操作的方法，包括一些其他问题解决办法，比如排序方法（冒泡排序、插入排序），都是有具体的算法的。算法的优劣，需要根据具体情况采用具体的解决办法，这才是最优的。&lt;/p&gt;
&lt;p&gt;刚才数据结构中提到的数据关系，其实是一种逻辑关系，真正在计算机中存储不同数据结构，都会有两种物理关系，顺序存储和链式存储。必定这种物理关系需要反应在语言上，顺序存储则对应数据类型中的一维数组，链式存储则是一系列指针类型。因此，实现不同数据结构都可以使用顺序存储和链式存储，则数据结构和采用实现的存储结构无直接关系。比如，对于线性结构的线性表，可以是顺序存储实现，称为顺序表，也可以是链式存储实现，称为链式表。&lt;/p&gt;
&lt;p&gt;当然，用不同存储方法实现数据结构后，对数据结构进行操作是有差异的。顺序存储最大的特点就是利于查找，即通过数组下标就可以快速完成，但是插入或是删除数据需要移动其他元素，复杂度O(n)；但是对于链式存储，插入和删除非常便利，因为是指针直接操作目标元素，不需要操作其他元素，但是对于查找等操作，却需要逐一遍历到目标元素才可以，不如顺序存储。虽然各有优劣，还是老话，需要根据实际情况选择合适的实现方式。&lt;/p&gt;
&lt;p&gt;一口气理清了数据结构、数据类型等概念，当做基础吧。为了更好理解和分析数据结构，后期一些基本数据结构估计大多数用C语言实现，可能一些算法，比如查找或是排序，重点在于方法和实现，就用Python等语言，便于实现。&lt;/p&gt;</summary><category term="数据结构，算法"></category></entry><entry><title>OVS源码分析----datapath消息处理</title><link href="http://ysywh.github.io/pages/2015/05/10/OVS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90----datapath%E6%B6%88%E6%81%AF%E5%A4%84%E7%90%86.html" rel="alternate"></link><updated>2015-08-30T17:30:00+08:00</updated><author><name>ysy</name></author><id>tag:ysywh.github.io,2015-05-10:pages/2015/05/10/OVS源码分析----datapath消息处理.html</id><summary type="html">&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;h3&gt;前言&lt;/h3&gt;
&lt;p&gt;当packet进入datapath无法匹配则通过netlink上交给用户态，处理完成后用户态会通过generic netlink与内核态进行交互，把流表项flow和packet发给内核态进行处理。下面分析内核态如何通过generic netlink接收flow与packet，并且进行相应处理。&lt;/p&gt;
&lt;p&gt;generic netlink：ovs的内核和用户态通过generic netlink(genl，泛型netlink，比netlink支持更多协议，功能更多)交互。genl任然是cs模式，内核为服务端，用户态为客户端（内核中还有一个genl控制器，属于内核态的客户端，用来分配通信通道）。类似socket，genl建立一系列通信通道，genl family对应这些通道，从而交互。&lt;/p&gt;
&lt;p&gt;通信前，作为服务端的内核态要定义family（指定信道类型）和operation（处理函数），并且进行注册，则客户端可以通过注册的信息与之交互。直接以ovs内核态为例分析：&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;一 内核态对flow的接收与处理&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;1 定义注册genl数据结构（datapath\datapth.c）：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;static struct genl_family dp_flow_genl_family = {
    .id = GENL_ID_GENERATE,
    .hdrsize = sizeof(struct ovs_header),
    .name = OVS_FLOW_FAMILY,
    .version = OVS_FLOW_VERSION,
    .maxattr = OVS_FLOW_ATTR_MAX,
     SET_NETNSOK
};
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个是genl family结构体定义，名字dp_flow_genl_family，用来处理flow的family。参数都是genl family结构体的部分属性，对其进行初始化。id和name即为family id和name。hdrsize定义ovs协议头长度，genl使用netlink标准的attr来传输数据。注意，客户端通过name就可以发送数据，让指定的family接收。如一种8的dpif_linux_flow_to_ofpbuf函数中，就会调用函数nl_msg_put_genlmsghdr，传入参数ovs_flow_family，从而制定了内核接收到的通道family。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;static struct genl_ops dp_flow_genl_ops[] = {
    { .cmd = OVS_FLOW_CMD_NEW,
      .flags = GENL_ADMIN_PERM, /* Requires CAP_NET_ADMIN privilege. */
      .policy = flow_policy,
      .doit = ovs_flow_cmd_new_or_set
    },…..
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个是genl operation的定义，名为dp_flow_genl_ops，主要用来定义对于flow的处理函数的定义。由于定义了数组，值罗列第一个genl ops。cmd是命令名字，可以看出处理函数的功能（这里主要是加入、更新或删除流表项flow），flag是属性设置，policy是接收到数据后，但没有触发事件处理函数之前所执行的过滤准则，比如对帧中数据attr的校验。doit是回调函数，generic netlink接收到数据触发，运行在进程上下文中，是对来自用户态数据进行执行操作的重点。doit函数接收skb和genl_info两个数据，skb即为触发此回调函数的socket buffer，genl_info结构体包含发送序号、发送客户端pid，头部指针和attrs(即经过genl_ops-&amp;gt;policy过滤后的结果，包含传递的数据。)。当然有的还有回调函数dumpit, dumpit与doit的区别是:dumpit的第一个参数skb不会携带从客户端发来的数据.
定义实例化完family和ops后，需要通过genl_register_family和genl_register_ops进行注册。这样则可以进行通信。&lt;/p&gt;
&lt;p&gt;2 调用处理函数进行流表项处理操作。
定义注册完famliy和ops，即可与用户态进行交互（用户态通过指定famliy指定通信通道，从而内核态接收数据会触发相应的ops回调函数进行处理）。下来分析来自用户态下发flow的流表项处理。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;static int ovs_flow_cmd_new_or_set(struct sk_buff *skb, struct genl_info *info)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个是内核态对于flow的增加或是更新（action更新）的处理函数。判断不存在相同流表项，则扩展table、分配流表项空间然后把流表项flow放入bucket中。存在的话则更新action即可。&lt;/p&gt;
&lt;p&gt;具体分析一下，首先需要把用户态传递过来的数据提取出来**a = info-&amp;gt;attrs，前面分析可知，传入参数info这个结构体数据成员attrs，attrs既是policy过滤后的数据。之后，调用函数ovs_flow_from_nlattrs，从a中提取key，调用validate_and_copy_actions把a中action放入变量acts（此处判断若为OVS_FLOW_CMD_NEW类型，即对于增加新流表项却没有action报错）。此后利用get_dp函数得到插入流表项的datapath（info-&amp;gt;userhdr-&amp;gt;dp_ifindex-&amp;gt;net_device -&amp;gt; vport -&amp;gt; datapath），继而找到相应流表table。&lt;/p&gt;
&lt;p&gt;为了确认是否已存在相同流表项，先查找流表项flow = ovs_flow_tbl_lookup(table, &amp;amp;key, key_len);主要通过在table中匹配key查找。先分析不存在flow为false，则进入加入新流表项if语句中，先排除不是更新流表项操作（OVS_FLOW_CMD_SET），然后调用函数ovs_flow_tbl_expand扩展流表table空间，方便之后添加新流表项，然后分配流表项空间ovs_flow_alloc。下来即重要函数ovs_flow_tbl_insert，其向bucket中插入流表项flow，调用ovs_flow_cmd_build_info构造回复用户层的通知消息。对于存在流表项即只更新action部分，不再赘述。&lt;/p&gt;
&lt;p&gt;对于ops中其他回调函数，如ovs_flow_cmd_del（删除流表项）原理一样，主要通过判断flow是否存在，存在则调用ovs_flow_tbl_remove (table, flow)函数删除流表项。&lt;/p&gt;
&lt;p&gt;3 插入流表项&lt;/p&gt;
&lt;p&gt;&lt;code&gt;void ovs_flow_tbl_insert(struct flow_table *table, struct sw_flow *flow,
             struct sw_flow_key *key, int key_len)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;关系：在ovs_flow_cmd_new_or_set中调用&lt;/p&gt;
&lt;p&gt;功能：插入流表项。&lt;/p&gt;
&lt;p&gt;数据结构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;sw_flow：流表项flow的数据结构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主要数据成员&lt;ul&gt;
&lt;li&gt;sw_flow_key类型的key:key可以称为查找key，就是匹配流表项的匹配域字段组合（port、优先级、l2-l4），&lt;/li&gt;
&lt;li&gt;sw_flow_actions类型的sf_acts:sf_acts用来存贮action的类型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;flow_table：流表结构体&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主要成员&lt;ul&gt;
&lt;li&gt;flex_array类型的bucket&lt;/li&gt;
&lt;li&gt;锁rcu_head的rcu。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;之前2中分析了内核态接收到消息，提取出key和action等，找出相应datapath和table，则向table中插入流表项，现在主要分析如何向table插入流表项flow。&lt;/p&gt;
&lt;p&gt;在ovs_flow_tbl_insert函数前，先调用函数rcu_assign_pointer(flow-&amp;gt;sf_acts, acts)把action插入到空白流表项flow的sf_acts（flow的action）字段中。则调用流表项插入函数ovs_flow_tbl_insert，传入table、流表项flow（目前只有action字段初始化了）、匹配域key等参数。函数中，调用函数ovs_flow_hash把key 进行hash后放入flow-&amp;gt;hash再通过memcpy函数把key复制到flow的key字段，即此时flow流表项就构成了，有了匹配域key和action两个重要部分。此时调用__flow_tbl_insert函数把flow插入table相应位置即可。函数中，先通过find_bucket函数，利用flow-&amp;gt;hash在table中找到应插入的哈希桶位置头部head，然后通过函数hlist_add_head_rcu把头部位置head写入flow-&amp;gt;hash_node参数即完成flow插入。可以看到flow中key的hash可以定位插入table的哈希桶位置。&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;二 内核态接收处理packet&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;内核态接受处理packet和接受处理flow原理类似，也是先定义注册generic netlink的family（name为OVS_PACKET_FAMILY）和ops，见用户层8）中调用函数dpif_linux_encode_execute发送packet包时，会指明OVS_PACKET_FAMILY通道，则会触发此通道的ops回调函数进行packet接收处理。下来详细对此回调函数ovs_packet_cmd_execute进行分析。&lt;/p&gt;
&lt;p&gt;1 内核态调用回调函数接收处理packet &lt;/p&gt;
&lt;p&gt;&lt;code&gt;static int ovs_packet_cmd_execute(struct sk_buff *skb, struct genl_info *info)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;位置：datapath/datapath.c&lt;/p&gt;
&lt;p&gt;调用memcpy函数把netlink接收到数据a的packet部分(应该是传统包内容)提取到packet参数中，a中还有action等字段。接下来会构造一个sw_flow结构体的flow来发送packet：&lt;/p&gt;
&lt;p&gt;调用ovs_flow_extract函数，从packet的以太网帧头中提取key部分构造流表项flow的匹配域key，此
外，还会调用函数ovs_flow_metadata_from_nlattrs直接从a的key字段解析补充flow的key，这些是a的packet中提取不到的一些字段（如tunnel id）。调用validate_and_copy_actions函数把actions提取到变量acts中，从而进一步利用函数rcu_assign_pointer把动作acts放入flow的action字段sf_acts中。此时匹配此packet的flow流表项构成。调用OVS_CB(packet)-&amp;gt;flow = flow;把flow放入packet的OVS_CB中（不理解？在后面处理packet时候可以直接关联找到此packet的action）。获取dp后调用函数ovs_execute_actions执行packet的动作。&lt;/p&gt;
&lt;p&gt;2 执行packet关联的所有action&lt;/p&gt;
&lt;p&gt;&lt;code&gt;int ovs_execute_actions(struct datapath *dp, struct sk_buff *skb)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;位置：datapath\actions.c&lt;/p&gt;
&lt;p&gt;最开始就直接通过acts = rcu_dereference(OVS_CB(skb)-&amp;gt;flow-&amp;gt;sf_acts)提取出packet（即skb）的所有actio n。然后函数do_execute_actions（datapath\actions）传入dp、skb和action对packet执行一系列actions。在函数do_execute_actions中，通过逐一循环判断action类型，从而执行相应的操作。&lt;/p&gt;
&lt;p&gt;这里主要讨论包处理类型为从端口输出，则会从packet中提取output端口号到参数pre_port，从而每次循环结束后调用do_output函数发送packet包，发送时候会对包进行克隆。&lt;/p&gt;
&lt;p&gt;在do_output函数中，通过调用函数ovs_vport_rcu，利用参数dp和out_port得到发送端口实体vport（datapath端口结构体），从而调用ovs_vport_send(vport, skb)把packet发送到指定vport。&lt;/p&gt;
&lt;p&gt;当然除了输出端口操作，还有push_vlan、pop_vlan、output_userspace（发送包到用户空间）等操作。对于发送用户空间会调用output_userspace函数，函数中调用ovs_dp_upcal（datapath\datapath.c）发送upcall消息，不再赘述。&lt;/p&gt;
&lt;p&gt;3 调用底层设备进行packet发送&lt;/p&gt;
&lt;p&gt;结构体：vport（datapath\vport.h）端口号、所属dp外有一个重要成员vport_ops，定义了端口所能执行的所有操作行为。&lt;/p&gt;
&lt;p&gt;vport_ops：定义datapath的端口vport的所有行为函数。如send，用来从设备发送packet。
首先初始化结构体vport_ops为ovs_netdev_vport_ops（datapath\vport-netdev.c）。定义了vport的所有操作函数，比如.send=netdev_send。
static int netdev_send(struct vport &lt;em&gt;vport, struct sk_buff &lt;/em&gt;skb)&lt;/p&gt;
&lt;p&gt;关系：在函数ovs_vport_send中，通过vport-&amp;gt;ops-&amp;gt;send(vport, skb)动态调用。&lt;/p&gt;
&lt;p&gt;函数中，通过skb-&amp;gt;dev = netdev_vport-&amp;gt;dev;得到设备，然后调用dev_queue_xmit(skb)函数把packet放入队列中发送。&lt;/p&gt;</summary><category term="OVS souce code"></category></entry><entry><title>OVS源码分析----用户层处理Upcall消息</title><link href="http://ysywh.github.io/pages/2015/05/10/OVS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90----%E7%94%A8%E6%88%B7%E5%B1%82%E5%A4%84%E7%90%86Upcall%E6%B6%88%E6%81%AF.html" rel="alternate"></link><updated>2015-08-30T17:30:00+08:00</updated><author><name>ysy</name></author><id>tag:ysywh.github.io,2015-05-10:pages/2015/05/10/OVS源码分析----用户层处理Upcall消息.html</id><summary type="html">&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;h3&gt;前言&lt;/h3&gt;
&lt;p&gt;当OVS内核接从端口到packet，会进行包解析提取出查询key，然后用key进行datapath中的流表匹配处理，对于以下两种情况1）没有匹配到流表项 2）匹配到的流表项动作为发往用户层，都会将packet和
key构造成Upcall消息，通过netlink通道发往用户层，用户态接收upcall消息后会进行处理，比如用户层流表匹配处理等。当然在用户层匹配到流表，会将流表项安装到内核层，达到相同流在内核层快速处理的目的：&lt;/p&gt;
&lt;p&gt;下俩将按照用户层接收upcall消息与处理的流程进行分析：&lt;/p&gt;
&lt;p&gt;用户层接收upcall消息，通过ofproto实体完成底层消息接收功能的。ofproto是ofproto_dpif类型数据结构，具有数据成员dpif（ofproto\ofproto-dpif.c）。通过ofproto—&amp;gt;dpif与内核交互数据。&lt;/p&gt;
&lt;p&gt;upcall处理流程如图:&lt;/p&gt;
&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;1）   upcall消息处理函数handle_upcalls(ofproto\ofproto-dpif.c)&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;static int handle_upcalls(struct ofproto_dpif *ofproto, unsigned int max_batch)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;功能&lt;/strong&gt;：接收upcall消息并对miss_upcall类型消息调用处理。&lt;/p&gt;
&lt;p&gt;函数中处理流程如下&lt;/p&gt;
&lt;p&gt;1 调用upcall消息接收函数：
    error = dpif_recv(ofproto-&amp;gt;dpif, upcall, buf);
 调用ofproto实体对应的成员组件实体dpif进行接收，把消息存入缓存buf中，并且把具体消息放入upcall中。具体分析见后。&lt;/p&gt;
&lt;p&gt;2 switch判断upcall消息的三种类型，并分别处理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于SFLOW_UPCALL消息，调用handle_sflow_upcall处理，并ofpbuf_uninit(buf)清除缓存。&lt;/li&gt;
&lt;li&gt;对于BAD_UPCALL消息，直接清除缓存。&lt;/li&gt;
&lt;li&gt;对于MISS_UPCALL消息（重点），计数后，跳出switch用handle_miss_upcalls进行处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3 对MISS_UPCALL消息调用handle_miss_upcalls进行着重处理。并紧后进行buf缓存清除。&lt;/p&gt;
&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;2）消息接收函数dpif_recv（lib\dpif.c）&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;int dpif_recv(struct dpif *dpif, struct dpif_upcall *upcall, struct ofpbuf *buf)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关系&lt;/strong&gt;：handle_upcalls中调用此函数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;功能&lt;/strong&gt;：与内核层通信获交互upcall消息。&lt;/p&gt;
&lt;p&gt;1 调用recv(dpif, upcall, buf)函数进行upcall消息接收，放入upcall中，至此得到upcall消息。其中通过指针dpif具体调用了底层的接收函数dpif_linux_recv（位于Lib\dpif-linux中），此函数中调用socket函数从内核汇总接收netlink的msg，存到ofpbuf中，即error = nl_sock_recv(ch-
&gt;sock, buf, false)，随后并调用error = parse_odp_packet(buf, upcall, &amp;amp;dp_ifindex)解析出upcall消息。&lt;/p&gt;
&lt;p&gt;2 &lt;code&gt;odp_flow_key_format(upcall-&amp;gt;key, upcall-&amp;gt;key_len, &amp;amp;flow)&lt;/code&gt;利用这个函数得到的upcall消息解析得到flow消息进行日志输出。&lt;/p&gt;
&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;3) miss_upcall消息处理函数&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;static void handle_miss_upcalls(struct ofproto_dpif *ofproto, struct dpif_upcall *upcalls,size_t n_upcalls)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关系&lt;/strong&gt;：handle_upcalls中被调用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;功能&lt;/strong&gt;：对miss_upcall消息具体进程处理。&lt;/p&gt;
&lt;p&gt;1 先利用for循环对upcall消息进行处理，为了从每个upcall的packet中提取出flow，然后比较flow，把具有相同flow的每个upcall的packet放入结构体flow_miss中，定义这个结构体变量为miss，然后对他们方便统一处理。&lt;/p&gt;
&lt;p&gt;循环中：利用函数ofproto_dpif_extract_flow_key从upcall消息中提取出flow（lib\flow.h中定义了这个数据结构），并利用函数flow_extract对flow的优先级、mark、in_port进行字段填充（实际中是对数据包协议各层进行逐层解析）。此后flow_hash(&amp;amp;miss-&amp;gt;flow, 0)对miss结构中的flow进行哈希处理，利用existing_miss = flow_miss_find(&amp;amp;todo, &amp;amp;miss-&amp;gt;flow, hash)把flow放入todo list的列表结构中。&lt;/p&gt;
&lt;p&gt;2 调用handle_flow_miss函数进行flow处理。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;handle_flow_miss(ofproto, miss, flow_miss_ops, &amp;amp;n_ops)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;传入ofproto和miss，对flow进行处理，得到处理结果类型flow_miss_ops，n_ops是得到的类型个数。得到处理类型用于后面根据这个类型进行处理。具体见函数。&lt;/p&gt;
&lt;p&gt;数据结构：flow_miss_op：此类型数据结构具有数据成员dpif_op这个数据结构（lib\dpif.c），定义了三种flow处理类型（dpif_flow_put\delete\execute）。&lt;/p&gt;
&lt;p&gt;3 调用&lt;code&gt;dpif_operate(ofproto-&amp;gt;dpif, dpif_ops, n_ops)&lt;/code&gt;函数，根据dpif_op中的处理类型进行分别三种处理（dpif_flow_put\delete\execute）。&lt;/p&gt;
&lt;p&gt;以上完成了从用户层获取upcall消息，并对MISS_UPCALL类型消息进行处理存入miss（结构体miss_flow）。至此，接下来要具体对miss进行处理（构造facet和对miss执行action）。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;接下来要具体对miss进行处理:&lt;/p&gt;
&lt;h4&gt;4）&lt;strong&gt;&lt;code&gt;static void handle_flow_miss(struct ofproto_dpif *ofproto, struct flow_miss *miss,struct flow_miss_op *ops, size_t *n_ops)&lt;/code&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;关系&lt;/strong&gt;：在handle_miss_upcalls中被调用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;功能&lt;/strong&gt;：判断是存在和flow相同的facet，不存在则根据实体的结构体ofproto_dpif-&amp;gt;rule和flow_miss-&amp;gt;flow创建facet。存在facet后进而对flow_miss进行处理。&lt;/p&gt;
&lt;p&gt;数据结构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;facet（ofproto\ofproto-dpif.c）： openflow flow的exact-match实体。个人理解是用户空间的流表实体，用来匹配upcall消息或是openflow消息的，然后执行动作，类比匹配传统流的流表。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主要数据成员&lt;ul&gt;
&lt;li&gt;struct rule_dpif *rule   &lt;/li&gt;
&lt;li&gt;struct list subfacets&lt;/li&gt;
&lt;li&gt;struct flow flow;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1 从ofproto（结构体ofproto_dpif）的成员facet表中找到与flow完全匹配的项。&lt;/p&gt;
&lt;p&gt;其中，&lt;code&gt;facet = facet_lookup_valid(ofproto, &amp;amp;miss-&amp;gt;flow, hash)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;实现是通过函数中调用facet = facet_find(ofproto, flow, hash)，facet_find通过存在的ofproto-&amp;gt; facets-&amp;gt;flow与flow相比，看是否完全相等，相等则返回在各方存在的facet。不存在否则返回空指针赋给facet。&lt;/p&gt;
&lt;p&gt;2 if判断facet存在性，如果存在直接调用handle_flow_miss_with_facet进行后续处理，否则（比如第一个upcall到达时候，这个才是常见情况）需要得到rules，进而创建一个facet，再调用handle_flow_miss_with_facet进行后续处理。&lt;/p&gt;
&lt;p&gt;创建facet,需要先得到rule:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;struct rule_dpif *rule = rule_dpif_lookup(ofproto, &amp;amp;miss-&amp;gt;flow)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;函数中，先通过rule_dpif_lookup__函数查找返回结构体为rule_dpif的规则rule。如果流表（？）中没有查找到，则通过rule_dpif_miss_rule函数创建rule，rule取值类型为结构体ofproto_dpif中的miss_rule或no_packet_in_rule类型。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;进入函数，这里有必要分析一下rule_dpif_miss_rule函数：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;static struct rule_dpif * rule_dpif_miss_rule(struct ofproto_dpif *ofproto, const struct flow *flow)&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据结构:rule_dpif，具有重要成员rule。&lt;ul&gt;
&lt;li&gt;rule：是一个包含结构体ofproto（可看做一个openflow交换机）的openflow flow(openflow流，可看做比如flowmod这种openflow流？)。最重要是具有ofpact（action头部）这个结构体。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;主要成员：最主要是 ofpact（action header，标注了action的类型等）。其次有成员hardtime，idle_timeout，table_id，flow_cookie等。&lt;/p&gt;
&lt;p&gt;rule_dpif_miss_rule函数中，通过判断选择返回rule_dpif的类型miss_rule或no_packet_in_rule。miss_rule类型代表发往控制器，no_packet_in_rule代表丢弃。&lt;/p&gt;
&lt;p&gt;这里可以分析一下port-&amp;gt;up.pp.config，化为结构体为ofproto_dpif-&amp;gt;ofport-&amp;gt;ofputil_phy_port-&amp;gt;ofputil_port_config。结构体ofport是openflow交换机的一个端口实体，调用物理端口抽象fputil_phy_port，有配置、状态、最大速率等参数成员，配置参数结构体ofputil_port_config有成员不允许转发、不允许flood等成员参数。&lt;/p&gt;
&lt;p&gt;3 通过2得到了rule，这里结合miss-&amp;gt;flow创建facet。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;facet = facet_create(rule, &amp;amp;miss-&amp;gt;flow, hash)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在这之前，有函数flow_miss_should_make_facet，判断是否在用户空间追踪安装datapath flow（不太理解，往往是不进入if内部）。接下来，则函数facet_create通过rule和flow创建facet，但却还没有subfacet，且相应action在rule中。&lt;/p&gt;
&lt;p&gt;4 至此寻找或是创建了facet，则有了和flow_miss匹配的facet，则对flow_miss具体处理，且其中增加datapath操作给ops，且更新计数n_ops。&lt;/p&gt;
&lt;p&gt;其中，&lt;code&gt;handle_flow_miss_with_facet(miss, facet, now, ops, n_ops)&lt;/code&gt;
具体分析此函数。目前有了和flow_miss匹配的facet，则具体对flow_miss进行处理&lt;/p&gt;
&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;5 ）&lt;code&gt;static void handle_flow_miss_with_facet(struct flow_miss *miss, struct facet *facet,long long int now,struct flow_miss_op *ops, size_t *n_ops)&lt;/code&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;关系&lt;/strong&gt;：在handle_flow_miss中最后被调用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;功能&lt;/strong&gt;：给facet创建subfacet，并且填充action动作，继而按照动作处理flow_miss。&lt;/p&gt;
&lt;p&gt;结构体：subfacet ：包含facet的action的dpif flow（A dpif flow and actions associated with a facet.）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主要成员
    -struct nlattr *actions; （Datapath actions）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1 创建facet的subfacet&lt;/p&gt;
&lt;p&gt;&lt;code&gt;subfacet = subfacet_create(facet,miss-&amp;gt;key_fitness, miss-&amp;gt;key, miss-&amp;gt;key_len,
                               miss-&amp;gt;initial_tci, now)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;函数中先判断facet的成员subfacet是否为空，不为空则直接返回subfacet，否则创建subfacet，并向subfacet中各个成员字段赋空值。则对于新建subfacet的action等成员都为空。之后，要依赖subfacet_make_actions函数创建action。&lt;/p&gt;
&lt;p&gt;2 填充subfacet的action字段，作为datapath action。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;subfacet_make_actions(subfacet, packet, &amp;amp;odp_actions)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;通过rule的action来构造subfacet的datapath action，并把action存入结构体为ofbuf缓存变量odp_actions中。&lt;/p&gt;
&lt;p&gt;函数中，具体先通过函数action_xlate_ctx_init，结合ofproto、flow、rule等初始化出action translate context这个上下文变量ctx。然后调用函数xlate_actions，结合参数ctx、rule等翻译出datapath action并放入odp_actions中，最后利用上下文ctx填充facet一些字段，利用存有action的odp_actions填充subfacet的actions字段。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;这里需要着重分析xlate_actions函数，因为其得到action并具体执行了flow_miss的action
（比如发往控制器）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;6）&lt;strong&gt;&lt;code&gt;static void xlate_actions(struct action_xlate_ctx *ctx, const struct ofpact *ofpacts, size_t ofpacts_len,struct ofpbuf *odp_actions)&lt;/code&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;关系&lt;/strong&gt;：在subfacet_make_actions中被最后调用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;功能&lt;/strong&gt;：利用上下文ctx把datapath action翻译到 odp_actions缓存里，action长度为rule中的ofpacts（action头部）标注的长度。然后执行动作。&lt;/p&gt;
&lt;p&gt;1 首先一个if switch语句进行packet分片处理。。。（？）&lt;/p&gt;
&lt;p&gt;2 &lt;code&gt;special = process_special(ctx-&amp;gt;ofproto, &amp;amp;ctx-&amp;gt;flow, ctx-&amp;gt;packet)&lt;/code&gt;
 判断packet类型是否为SLOW_CFM（连通性故障管理协议）、SLOW_LACP（链路聚合协议）、SLOW_STP，如果是则直接在判断语语句中进行相应处理(slow path)，然后返回相应类型，否则返回0(fast path)，等待后续处理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解释slow path:这里需要注意，用户层对于上交包的处理，分为slow通道和非slow通道（ctx的slow参数，0则为fast path，非0则为slow path）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;变量slow为enum slow_path_reason（lib\odp-util.h），通过看enum枚举可以看到slow path原因：SLOW_CFM、SLOW_LACP、 SLOW_STP、SLOW_IN_BAND（inband模式）等六种packet情况都走slow path。&lt;/p&gt;
&lt;p&gt;3 紧接根据special判断是否为CFM，LACP，STP包，若是则ctx-&amp;gt;slow与相应类似包标志位做或运算，初始化slow path原因，若不是则利用函数do_xlate_actions（根据rule-&amp;gt;up.ofpacts）执行具体的action。这个极其重要，具体分析见后。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;以上对于upcal上来的类型为flow_miss的packet，寻找匹配的facet或是因为第一个packet无法匹配而构造facet（利用rule、flow构造facet、subfacet，利用rule中action构造subfacet的action字段），接下来则重点根据rule-&amp;gt;up.ofpacts类型来执行动作处理上交的包。&lt;/p&gt;
&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;h4&gt;7）&lt;strong&gt;&lt;code&gt;static void do_xlate_actions(const struct ofpact *ofpacts, size_t ofpacts_len,struct action_xlate_ctx *ctx)&lt;/code&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;关系&lt;/strong&gt;：在xlate_actions中被调用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;功能&lt;/strong&gt;：对于上交到用户层的包，根据rule-&amp;gt;up.ofpacts的action类型来执行相应的动作。&lt;/p&gt;
&lt;p&gt;结构体：ofpact：action的头部，属于rule的一个数据成员。（lib\ofp-actions.h）&lt;/p&gt;
&lt;p&gt;数据成员：action类型type、ofputil_action_code和len。其中type是ovs的action类型（如
output类型、Header changes等action类型）。&lt;/p&gt;
&lt;p&gt;1 首先利用函数get_ofp_port得到端口的实现实例port（ofport_dpif类型，ofport_dpif中有ofport类型成员，是一个openflow端口）。紧接着if判断，如果forwarding和learning都是disable，则对包执行drop动作。否则继续执行后面。&lt;/p&gt;
&lt;p&gt;2 进入循环，用switch (a-&amp;gt;type)判断动作类型并执行相应动作。这里特别分析action type为output时的动作执行（如对于第一个包交往控制器则要执行这个动作）。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;xlate_output_action(ctx, ofpact_get_OUTPUT(a)-&amp;gt;port,ofpact_get_OUTPUT(a)-&amp;gt;max_len, true)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;先用ofpact_get_OUTPUT(a)-&amp;gt;port得到具体端口类型（如controller），然后调用xlate_output_action函数执行动作。&lt;/p&gt;
&lt;p&gt;进入xlate_output_action函数可以看到switch语句，output类型端口有in_port、table/normal、controller、flood等。对于发往controller，执行execute_controller_action函数，跟踪内部，会发现调用packin类似函数发往controller。&lt;/p&gt;
&lt;h2&gt;&lt;/br&gt;&lt;/h2&gt;
&lt;p&gt;以上对于flow_miss，完成了创建rule、facet、subfacet、action即动作的执行，但最终需要用socket完成数据传输，完成真正的执行动作。因此，需要回顾3），handle_flow_miss函数处理完后，需要根据datapath执行类型进行执行，调用函数dpif_operate。在此做简单分析。
&lt;/br&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;8）&lt;code&gt;void dpif_operate(struct dpif *dpif, struct dpif_op **ops, size_t n_ops)&lt;/code&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;关系&lt;/strong&gt;：在函数handle_miss_upcalls最后被调用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;功能&lt;/strong&gt;：根据之前得到的datapath操作类型批量处理，通过nla发到内核，从而让内核可以真正执行操作，发送完并接收回应来更新统计信息。&lt;/p&gt;
&lt;p&gt;数据结构：dpif_op：datapath操作类型。数据成员有三种操作类型的数据结构成员：dpif_flow_put、dpif_flow_del、dpif_execute。&lt;/p&gt;
&lt;p&gt;这三种操作类型的数据结构中基本都有重要的成员：dpif_flow_put（成员key和actions）、dpif_flow_del（成员key），dpif_execute（成员key、actions和packet）。成员key是待要进行put或是delete的flow（流表项），packet（对于dpif_exacute）是要进行执行的packet。&lt;/p&gt;
&lt;p&gt;dpif_operate函数调用dpif-&amp;gt;dpif_class-&amp;gt;operate(dpif, ops, n_ops)进行批量处理，没有处理的之后再以根据操作类型依次处理。dpif-&amp;gt;dpif_class-&amp;gt;operate(dpif, ops, n_ops)具体动态调用了dpif_linux_operate（lib\dpif-linux.c），而在dpif_linux_operate中调用dpif_linux_operate__循环处理，此函数中有具体处理过程。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;static void dpif_linux_operate__(struct dpif *dpif_, struct dpif_op **ops, size_t n_ops)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;根据处理三种处理类型，循环遍历所有操作ops（带有即将处理key和action）,将key与action放入缓存request中。之后执行socket与内核通信。&lt;/p&gt;
&lt;p&gt;1 先定义变量 *txnsp[MAX_OPS]，其为nl_transaction结构体（具有类型为ofpbuf的request和reply缓存变量），request为发送缓存，reply为接收缓存。Txnsp用来表征内核层与用户层之间的一次通信。真正socket连接通信时候会调用。&lt;/p&gt;
&lt;p&gt;2 根据操作类型分别处理，主要是想把action和key(excute类型还有packet)放入aux的request缓存中，方便以后传到txnps中再进行发送。根据是处理flow（增加或删除流表项）还是packet（packet关联原始经过交换机的传统包内容）操作分为三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;第一种：put流表项flow。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;dpif_linux_init_flow_put(dpif_, put, &amp;amp;flow)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这里主要是把变量put内容（主要是action和key，key内容即为流表项flow）传到flow变量中（其中通过前面put = &amp;amp;op-&amp;gt;u.flow_put把ops中key和action传到put中）。&lt;/p&gt;
&lt;p&gt;dpif_linux_flow_to_ofpbuf(&amp;amp;flow, &amp;amp;aux-&amp;gt;request)&lt;/p&gt;
&lt;p&gt;函数中又进一步把ovsheader和flow中的key与action填充到发送缓存request中（通过调用ofpbuf_put_uninit和nl_msg_put_unspec），从而得到与内核层交互发送信息。&lt;/p&gt;
&lt;p&gt;函数中，还制定了内核中数据接收通道famliy名字，从而指定此类消息被内核什么处理函数接收处理。利用函数nl_msg_put_genlmsghdr(buf, 0, ovs_flow_family…即内核接收family为ovs_flow_family（内核中数据交互前已经注册好，用户态直接连接交互即可）。
- 第二种：delete流表项flow，这与第一种相同，不过缺少像put操作存入缓存的action。
- 第三种：packet的处理&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;dpif_linux_encode_execute(dpif-&amp;gt;dp_ifindex, execute,&amp;amp;aux-&amp;gt;request)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个函数和前两种类似，不过直接通过execute = &amp;amp;op-&amp;gt;u.execute;把内容传到excute变量，再通过函数传到aux-&amp;gt;request缓存（主要传入有key、packet和action，特别packet）。&lt;/p&gt;
&lt;p&gt;3 &lt;code&gt;nl_sock_transact_multiple(genl_sock, txnsp, n_ops)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;与内核层建立socket的netlink连接，发送txnsp的request中信息（通过2中的aux传到txnsp中）并且接收来自内核的消息到reply中。参数genl_sock是netlink的socket, txnsp即表征内核层与用户层的一次连接，txnsp含有成员request和reply。&lt;/p&gt;
&lt;p&gt;函数中，具体调用了nl_sock_transact_multiple__函数，此函数中有发送函数sendmsg(sock-&amp;gt;fd, &amp;amp;msg, 0)和接收函数nl_sock_recv__(sock, buf_txn-&amp;gt;reply, false)，分别发送了缓存request
的信息并接收到reply缓存中，此后更新统计。&lt;/p&gt;
&lt;p&gt;至此，用户层信息发送到内核层，内核层真正执行动作。内核层和用户层交互完成。&lt;/p&gt;</summary><category term="OVS souce code"></category></entry><entry><title>OVS源码分析----OpenFlow消息处理</title><link href="http://ysywh.github.io/pages/2015/05/02/OVS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%E2%80%94%E2%80%94OpenFlow%E6%B6%88%E6%81%AF%E5%A4%84%E7%90%86.html" rel="alternate"></link><updated>2015-08-30T17:30:00+08:00</updated><author><name>ysy</name></author><id>tag:ysywh.github.io,2015-05-02:pages/2015/05/02/OVS源码分析————OpenFlow消息处理.html</id><summary type="html">&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;OVS作为交换机，可以通过安全通道与控制器进行消息交互。控制器向OVS下发Openflow消息，可以完成对数据层面策略下发，流控制等功能。OVS接收到控制器下发的Openflow消息，需要对其进行接收，解析与处理，如安装流表项等操作。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;下文按照OVS接收处理openflow消息的处理流程进行分析：&lt;/p&gt;
&lt;p&gt;handle_openflow(ofproto\ofproto.c)开始对openflow消息进行具体处理，因此这个函数开始进行分析。首先说明一个重要数据结构。&lt;/p&gt;
&lt;p&gt;数据结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ofconn(ofproto\connmgr.c)：代表ovs和控制器之间的一次openflow连接。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;主要的成员&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;connmgr（连接管理器）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rconn（一次可靠地openflow连接）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;1 static bool  handle_openflow(struct ofconn *ofconn, struct ofpbuf *ofp_msg)&lt;/h4&gt;
&lt;p&gt;接收控制器下发的openflow消息，并且调用函数handle_openflow__进行消息类别判断，做出对应的处理。若接收到错误的openflow消息则会返回error，向控制器发“error消息”进行回复。&lt;/p&gt;
&lt;h4&gt;2 satic enum ofperr handle_openflow__(struct ofconn *ofconn, const struct ofpbuf *msg)&lt;/h4&gt;
&lt;p&gt;数据结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ofp_header：openflow消息packets头部。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据成员&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;version（openflow消息版本号）&lt;/li&gt;
&lt;li&gt;type（openflow消息类型）&lt;/li&gt;
&lt;li&gt;length(openflow消息长度)&lt;/li&gt;
&lt;li&gt;xid（每次openflow消息id号，回复使用相同xid）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;先从接收到的消息msg中提取出openflow消息头部msg-&amp;gt;data，赋值给oh。oh利用函数ofptype_decode获得openflow消息类型type（枚举型ofptype中罗列了各种消息类型，lib\ofp-msgs.h）。通过判别type找到与消息类型相符的具体消息处理函数，从而进行消息处理。比如下面详细分析一下flowmod消息。&lt;/p&gt;
&lt;h4&gt;3 static enum ofperr handle_flow_mod(struct ofconn *ofconn, const struct ofp_header *oh)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;数据结构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ofputil_flow_mod（lib\ofp-util.h）：flowmod消息的数据结构&lt;ul&gt;
&lt;li&gt;数据成员&lt;ul&gt;
&lt;li&gt;match: 匹配域定义和掩码定义（match有两个成员flow（定义了可以匹配的各个字段）和flow_wildcards（bit掩码）)&lt;/li&gt;
&lt;li&gt;priority，cookie，command，buffer_id,out_port和&lt;/li&gt;
&lt;li&gt;ofpact：ofpact是action的头部，含有type等成员&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过函数ofpbuf_use_stub给ofpacts分配一块缓存opfbuf，然后通过调用函数ofputil_decode_flow_mod得到数据结构ofputil_flow_mod实体fm和实体ofpacts，则此时fm即包含flowmod消息格式的各个字段内容，而ofpacts缓存中含有action，并其中fm中的成员ofpacts指向这个缓存ofpacts。最后调用函数handle_flow_mod__，函数中，根据flowmod消息fm的command类型不同（五种），选择command相应流表项处理函数，在用户空间插入、修改或是删除流表项。&lt;/p&gt;
&lt;h4&gt;4 static enum ofperr add_flow(struct ofproto *ofproto, struct ofconn *ofconn,const struct ofputil_flow_mod *fm, const struct ofp_header *request)&lt;/h4&gt;
&lt;p&gt;选择flowmod指定id的表，根据flowmod消息创建分类流规则rule，并且插入rule，等再有相同流过来进行匹配，从而创建流表项。具体如下：&lt;/p&gt;
&lt;p&gt;先通过fm-&amp;gt;table_id获得flowmod指定id的流表，如果id号大于指定的最大流表数则会返回相应error类型。找到table id后，根据函数rule_alloc()分配一个分类器rule，随后调用函数cls_rule_init(&amp;amp;rule-&amp;gt;cr, &amp;amp;fm-&amp;gt;match, fm-&amp;gt;priority)填充rule-&amp;gt;cr，则rule的匹配域和优先级字段基本填充完成。之后进行冲突检测（check for overlap），防止重复添加相同rule。之后对rule各个字段进行填充，调用函数oftable_replace_rule插入这个初始化好的rule。&lt;/p&gt;
&lt;p&gt;这样addflow任务基本完成，等待以后相同流在核心层匹配失败后，upcall到用户层，则会根据匹配这个rule进行流表项的建立工作，如果不存在匹配的rule，则会丢弃或是上交controller，具体见用户态处理upcall消息分析。至于modify和delete类型flowmod消息，基本分析相同，如对command为modify的flowmod消息，则修改指定rule的action。&lt;/p&gt;</summary><category term="OVS souce code"></category></entry><entry><title>Cbench测试Opendaylight性能</title><link href="http://ysywh.github.io/pages/2015/04/03/Cbench%E6%B5%8B%E8%AF%95Opendaylight%E6%80%A7%E8%83%BD.html" rel="alternate"></link><updated>2015-08-30T17:30:00+08:00</updated><author><name>ysy</name></author><id>tag:ysywh.github.io,2015-04-03:pages/2015/04/03/Cbench测试Opendaylight性能.html</id><summary type="html">&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;要求和目标：用Cbench测试Opendaylight控制器的吞吐量和延时性能，拓扑简单设定为四个交换机&lt;/p&gt;
&lt;p&gt;实验通过Cbench模拟出拓扑，并对Opendaylight进行测试。&lt;/p&gt;
&lt;h3&gt;一：测试平台：&lt;/h3&gt;
&lt;p&gt;由于测试结果和测试平台的性能紧密联系，因此记录下测试平台参数。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;硬件参数：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CPU: Intel(R) Xeon(R) CPU E5-2609 0 @ 2.40GHz&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Memory: 8GB DDR3 - 1600 Mhz&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;软件参数:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OS: Ubuntu 14.04&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Java: OpenJDK java version "1.7.0"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Opendaylight版本:Helium-SR2&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Opendaylight设置为初始默认值&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;二：测试步骤&lt;/h3&gt;
&lt;p&gt;准备工作：先安装好&lt;a href="https://www.opendaylight.org/downloads"&gt;OpenDaylight&lt;/a&gt;和&lt;a href="https://github.com/deepurple/cbench-src"&gt;Cbench&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;1 开启opendaylight:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench1.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 安装Opendaylight控制器测试组件：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench2.png" /&gt;&lt;/p&gt;
&lt;p&gt;说明：Opendaylight不同于其他控制器，需要测试组件的支持，且测试组件具有两种测试模式：RPC和data store模式（区别见最后说明），以下分别用Cbench进行吞吐量和延时的测试.&lt;/p&gt;
&lt;h3&gt;RPC模式性能测试&lt;/h3&gt;
&lt;p&gt;首先，在RPC模式下进行Opendaylight性能测试：&lt;/p&gt;
&lt;p&gt;1 在opendaylight中开启RPC模式的测试组件：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench3.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 开启Cbench，测试控制器吞吐量(throughput)性能:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench4.png" /&gt;&lt;/p&gt;
&lt;p&gt;这里简单说明一下参数意义，s是交换机数量，M是每个交换机连接的主机数量，m是每次测试周期，l是测试循环次数，-t是进行吞吐量throughput测试，没有t则是延时latency测试。后面测试命令不再赘述。&lt;/p&gt;
&lt;p&gt;吞吐量测试结果截图：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench5.png" /&gt;&lt;/p&gt;
&lt;p&gt;测试结果简单解释：截图第二行显示测试性能的方面，可以看到是throughout，则是吞吐量测试。测试结果有10行数据，每行代表一次测试，每行有4个结果，单位是秒，代表每个交换机的测试结果，最后会有每毫秒的结果。最后一行是测试总的结果。&lt;/p&gt;
&lt;p&gt;3 开启Cbench，测试控制器延时（latency）性能：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench6.png" /&gt;&lt;/p&gt;
&lt;p&gt;测试结果截图：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench7.png" /&gt;&lt;/p&gt;
&lt;p&gt;特别说明：延迟测试结果要对测试的结果取倒数才是延迟。&lt;/p&gt;
&lt;h3&gt;data store模式性能测试&lt;/h3&gt;
&lt;p&gt;其次，在data store模式下进行Opendaylight性能测试:&lt;/p&gt;
&lt;p&gt;1关闭RPC模式，开启data store模式的测试组件：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench8.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 开启Cbench，测试控制器吞吐量(throughput)性能:&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench9.png" /&gt;&lt;/p&gt;
&lt;p&gt;吞吐量测试结果截图：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench10.png" /&gt;&lt;/p&gt;
&lt;p&gt;3 开启Cbench，测试控制器延时（latency）性能：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench11.png" /&gt;&lt;/p&gt;
&lt;p&gt;延迟测试结果截图：&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="http://7xnkv8.com1.z0.glb.clouddn.com/cbench12.png" /&gt; &lt;/p&gt;
&lt;h3&gt;说明&lt;/h3&gt;
&lt;p&gt;1 两种模式特别说明，来自Opendaylight官网：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;RPC : programming flows directly through an RPC to the OF Plugin&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;data store : programming flows by writing them into the MD-SAL config space, from where they are picked up by the FRM and programmed into the plugin)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2 参数命令和结果截图说明见4和5，之后的不再赘述。&lt;/p&gt;
&lt;p&gt;3 测试结果的文本数据，见附件result.txt&lt;/p&gt;</summary><category term="Cbench OpenDaylight"></category></entry><entry><title>Docker搭建Hadoop集群环境和Wordcount实验</title><link href="http://ysywh.github.io/pages/2015/03/11/Docker%E6%90%AD%E5%BB%BAHadoop%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E5%92%8CWordcount%E5%AE%9E%E9%AA%8C.html" rel="alternate"></link><updated>2015-08-19T17:30:00+08:00</updated><author><name>ysy</name></author><id>tag:ysywh.github.io,2015-03-11:pages/2015/03/11/Docker搭建Hadoop集群环境和Wordcount实验.html</id><summary type="html">&lt;p&gt;2015-3-8 by ysy   &lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;利用docker搭建Hadoop环境，并且完成Mapreduce中Word count实验  &lt;/p&gt;
&lt;hr /&gt;
&lt;h4&gt;一：实验目标&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;学习docker基本命令&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;搭建只有一个master和两个slave的Hadoop集群环境&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;进行wordcount实验,理解mapreduce和hdfs等工作机制&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;二：docker基本命令&lt;/h4&gt;
&lt;p&gt;docket是目前较为流行的虚拟化技术，可以方便轻松的在Linux中建立容器，达到虚拟化需求。&lt;/p&gt;
&lt;p&gt;基本操作命令如下，更多参考&lt;a href="!http://dockerpool.com/static/books/docker_practice/index.html"&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;启动容器：&lt;code&gt;docker run 镜像名&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;暂停容器：&lt;code&gt;docker stop 容器名&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重启开启容器：&lt;code&gt;docker start 容器名&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;进入容器：&lt;code&gt;docker attach 容器名&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;三：Hadoop集群环境搭建&lt;/h4&gt;
&lt;p&gt;1 Hadoop集群分为一个master和两个slave，因此依次用docker开启相应容器,其中需要做端口映射：&lt;/p&gt;
&lt;p&gt;&lt;img alt="1" src="http://gitlab.local/uploads/course/course_hadoop/955c4756f3/1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="2" src="http://gitlab.local/uploads/course/course_hadoop/7ce0511f3b/2.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="3" src="http://gitlab.local/uploads/course/course_hadoop/3ef073ba31/3.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 利用命令编辑： &lt;code&gt;vi /etc/hosts&lt;/code&gt;,加入master和两个slave的容器号和ip。之后需要 &lt;strong&gt;开启sshd服务&lt;/strong&gt; ，使其生效：' service  sshd start '&lt;/p&gt;
&lt;p&gt;&lt;img alt="4" src="http://gitlab.local/uploads/course/course_hadoop/d29157c596/4.png" /&gt;&lt;/p&gt;
&lt;p&gt;3 分别登陆master和slave，利用命令chkconfig命令查看服务&lt;/p&gt;
&lt;p&gt;&lt;img alt="5" src="http://gitlab.local/uploads/course/course_hadoop/83312aa0f6/5.png" /&gt;&lt;/p&gt;
&lt;p&gt;4 master上开启相应服务：&lt;/p&gt;
&lt;p&gt;开启Hadoop服务：service hadoop-hdfs-namenode start&lt;/p&gt;
&lt;p&gt;开启mapreduce服务：service hadoop-yarn-resourcemanager start&lt;/p&gt;
&lt;p&gt;开启任务记录的服务：service hadoop-mapreduce-historyserver start&lt;/p&gt;
&lt;p&gt;&lt;img alt="6" src="http://gitlab.local/uploads/course/course_hadoop/6e2e318e55/6.png" /&gt;&lt;/p&gt;
&lt;p&gt;5 在两个slave上分别开启Hadoop服务和mapreduce服务：&lt;/p&gt;
&lt;p&gt;service hadoop-hdfs-datanode start&lt;/p&gt;
&lt;p&gt;service hadoop-yarn-nodemanager start&lt;/p&gt;
&lt;p&gt;&lt;img alt="7" src="http://gitlab.local/uploads/course/course_hadoop/3a2cf8df6a/70.png" /&gt;&lt;/p&gt;
&lt;p&gt;6 三项服务分别可以在web端验证服务是否正确打开。至此，hadoop集群环境搭建完毕&lt;/p&gt;
&lt;p&gt;192.168.59.103:50070&lt;/p&gt;
&lt;p&gt;192.168.59.103:8088&lt;/p&gt;
&lt;p&gt;192.168.59.103:19888&lt;/p&gt;
&lt;p&gt;&lt;img alt="8" src="http://gitlab.local/uploads/course/course_hadoop/2ff2b313c1/8.png" /&gt;&lt;/p&gt;
&lt;h4&gt;三：Word count实验&lt;/h4&gt;
&lt;p&gt;word count 实验就是利用Mapreduce框架，对文本中的单词进行数量统计。&lt;/p&gt;
&lt;p&gt;1 建立一个text文件，写入内容，并put入hdfs文件系统后命名为wordcount.input文件，并查看其内容：&lt;/p&gt;
&lt;p&gt;&lt;img alt="9" src="http://gitlab.local/uploads/course/course_hadoop/47c3b12887/7.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 利用Wordcount脚本进行单词计数的简单实验,经过map和reduce等操作把经过输出到Wordcount.output中:&lt;/p&gt;
&lt;p&gt;&lt;img alt="10" src="http://gitlab.local/uploads/course/course_hadoop/f93f01d942/9.png" /&gt;&lt;/p&gt;
&lt;p&gt;3 登陆web可以观察任务状态，在输出文件中查看Wordcount结果，和预想结果相同，试验成功：&lt;/p&gt;
&lt;p&gt;&lt;img alt="11" src="http://gitlab.local/uploads/course/course_hadoop/7bd9c88362/8.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="12" src="http://gitlab.local/uploads/course/course_hadoop/bccbdf2a9e/10.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="13" src="http://gitlab.local/uploads/course/course_hadoop/9b7e274748/11.png" /&gt;&lt;/p&gt;
&lt;h4&gt;四：心得&lt;/h4&gt;
&lt;p&gt;1 对hdfs文件系统有了基本了解，利用简单的Wordcount实验对map和reduce有了直观认识，深觉此技术的有用性&lt;/p&gt;
&lt;p&gt;2 虽然完成本次试验，但是简单的实验还不能对Hadoop有更深刻的学习，希望今后学习其架构及其源码，多做实验达到学习的目的&lt;/p&gt;
&lt;p&gt;3 最后简单记录一下遇到的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;每次开启容器后，ip可能会发生变化，要记得修改hosts文件，否则会出现 &lt;code&gt;Hadoop fs shell&lt;/code&gt; 无法操作的问题&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其次，需要关闭安全模式，这样才可以向hdfs文件系统中put内容等操作 &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="mapreduce"></category><category term="word count"></category></entry><entry><title>MapReduce之letter count</title><link href="http://ysywh.github.io/pages/2015/03/02/MapReduce%E4%B9%8Bletter%20count.html" rel="alternate"></link><updated>2015-10-01T17:30:00+08:00</updated><author><name>ysy</name></author><id>tag:ysywh.github.io,2015-03-02:pages/2015/03/02/MapReduce之letter count.html</id><summary type="html">&lt;p&gt;2015-3-2 by ysy  &lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;本节在安装好的Eclipse环境中，尝试使用 MapReduce编程环境，运行letter count代码进行学习验证。letter count 实验就是对一段英文中出现的每个字母进行数量统计，比较基础的练习。&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;1 创建新的工程lettercount,并且加载需要的Hadoop库：&lt;/p&gt;
&lt;p&gt;&lt;img alt="1" src="http://gitlab.local/uploads/course/course_hadoop/bf8af6a841/1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="2" src="http://gitlab.local/uploads/course/course_hadoop/3e50a19c6b/2.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="3" src="http://gitlab.local/uploads/course/course_hadoop/b465f66e7d/3.png" /&gt;&lt;/p&gt;
&lt;p&gt;2 在网上寻找一个mapreduce的Wordcount代码文件，在map类中添加计算letter的代码，并且注释掉计算word的代码，加上对每个字母进行统计的代码，map输出键值对为（字母，one)，在reduce中进行合计，于统计word思路相同：&lt;/p&gt;
&lt;p&gt;&lt;img alt="5" src="http://gitlab.local/uploads/course/course_hadoop/acaaa07b4e/5.png" /&gt;&lt;/p&gt;
&lt;p&gt;3 运行前添加输入和输入文件，输入文件内容是一段英文，经过mapreduce运行计算后会把letter计算结果输出到输出文件中：&lt;/p&gt;
&lt;p&gt;&lt;img alt="4" src="http://gitlab.localuploads/course/course_hadoop/84a81d19fc/4.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="6" src="http://gitlab.local/uploads/course/course_hadoop/9754fce9ef/6.png" /&gt;&lt;/p&gt;
&lt;p&gt;4 通过export输出jar包，然后导入带有Hadoop的Linux系统中，进行实际运行计算：&lt;/p&gt;
&lt;p&gt;&lt;img alt="7" src="http://gitlab.local/uploads/course/course_hadoop/a1c5c158d1/7.png" /&gt;&lt;/p&gt;
&lt;p&gt;5 可以通过对比输入文件内容，比较计算的输出的结果，输出文件为两个：&lt;/p&gt;
&lt;p&gt;&lt;img alt="8" src="http://gitlab.local/uploads/course/course_hadoop/f70bf9a61c/8.png" /&gt;&lt;/p&gt;</summary><category term="mapreduce"></category><category term="letter count"></category></entry></feed>