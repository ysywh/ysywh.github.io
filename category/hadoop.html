<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="utf-8">
    <title>YsY记录点滴</title>
    <meta name="description" content="">
    <meta name="author" content="yansy">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
    <script src="http://ysywh.github.io/theme/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="http://ysywh.github.io/theme/bootstrap.min.css" rel="stylesheet">
    <link href="http://ysywh.github.io/theme/bootstrap.min.responsive.css" rel="stylesheet">
    <link href="http://ysywh.github.io/theme/local.css" rel="stylesheet">
    <link href="http://ysywh.github.io/theme/pygments.css" rel="stylesheet">

    <!-- So Firefox can bookmark->"abo this site" -->
        <link href="http://ysywh.github.io/feeds/all.atom.xml" rel="alternate" title="YsY记录点滴" type="application/atom+xml">
        <link href="http://ysywh.github.io/feeds/all.rss.xml" rel="alternate" title="YsY记录点滴" type="application/rss+xml">

</head>

<body>

<div class="navbar">
    <div class="navbar-inner">
    <div class="container">

         <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
             <span class="icon-bar"></span>
             <span class="icon-bar"></span>
             <span class="icon-bar"></span>
         </a>

        <a class="brand" href="http://ysywh.github.io">YsY记录点滴</a>

        <div class="nav-collapse">
        <ul class="nav">
            <li><a href="http://github.com">SDN</a></li>
            
            <li><a href="http://ysywh.github.io/pages/About me.html">About Me</a></li>
        </ul>
        </div>
        
    </div>
    </div>
</div>

<div class="container">
    <div class="content">
    <div class="row">

        <div class="span9">
        

        


    <div class='article'>
        <div class="content-title">
            <a href="http://ysywh.github.io/pages/2015/06/03/Mapreduce API 操作HBase.html"><h1>Mapreduce API 操作HBase</h1></a>
2015-06-03

by <a class="url fn" href="http://ysywh.github.io/author/ysy.html">ysy</a>
 


 
        </div>
        
        <div><h3><strong>前言</strong></h3>
<p>之前博文采用shell直接操作Hbase，这次通过一些API函数对habse进行操作。主要完成：</p>
<ul>
<li>
<p>用JAVA API完成对hbase表的建立、删除、数据添加与查看等基本操作</p>
</li>
<li>
<p>用MapReduce完成hdfs数据向habse表的导入</p>
</li>
</ul>
<p>通过写java代码，打成jar包，然后直接运行即可。</p>
<h3><strong>一 用JAVA API完成对hbase表的建立、删除、数据添加与查看等基本操作</strong></h3>
<p>这里只对简单的几个操作函数（建表，添加数据）进行分析，其他类似：</p>
<p>其中用到了几个和Hbase相关的类（HBaseAdmin、HBaseConfiguration、HTable、HTableDescriptor、Put、Get、Scanner等）与其成员函数，具体含义可以看这个<a href="http://blog.csdn.net/lifuxiangcaohui/article/details/39997205">链接</a>，讲解很明白。</p>
<p>1 建立管理habse的接口对象</p>
<div class="highlight"><pre>public class hbase{
static Configuration conf = HBaseConfiguration.create();
static HBaseAdmin admin;
public static void main(String[] args){
    try {
        admin = new HBaseAdmin(conf);
    } catch (IOException e) {
        e.printStackTrace();
    }

    createTable(&quot;access_yansiyu2&quot;);
    addRow(&quot;access_yansiyu2&quot;);
    ...
    }
...
}
</pre></div>


<p>分析：先得到一个缺省的“配置”对象conf，然后用类HBaseAdmin构造对象admin,HBaseAdmin提供了管理HBase数据库的表信息的接口，因此之后通过操作admin就可以对表进行部分操作，比如建立、删除表等。但是，对于向表中添加删除数据等操作用HTable类对象进行操作，后面会遇到。</p>
<p>类HBaseAdmin有很多表操作的api成员函数，比如createTable创建表，deleteTable删除表，添加列addColumn,enableTable使表有效，使表无效disableTable等等。</p>
<p>2 创建表</p>
<div class="highlight"><pre><span class="nt">public</span> <span class="nt">static</span> <span class="nt">void</span> <span class="nt">createTable</span><span class="o">(</span><span class="nt">String</span> <span class="nt">tablename</span><span class="o">)</span><span class="p">{</span>
    <span class="n">try</span> <span class="err">{</span>
        <span class="n">if</span><span class="p">(</span><span class="n">admin</span><span class="o">.</span><span class="n">tableExists</span><span class="p">(</span><span class="n">tablename</span><span class="p">))</span><span class="err">{</span>  
            <span class="n">System</span><span class="o">.</span><span class="n">out</span><span class="o">.</span><span class="n">println</span><span class="p">(</span><span class="s2">&quot;table is existed&quot;</span><span class="p">);</span>
        <span class="p">}</span><span class="nt">else</span><span class="p">{</span>  
            <span class="n">HTableDescriptor</span> <span class="n">desc</span> <span class="o">=</span> <span class="n">new</span> <span class="n">HTableDescriptor</span><span class="p">(</span><span class="n">Bytes</span><span class="o">.</span><span class="n">toBytes</span><span class="p">(</span><span class="n">tablename</span><span class="p">));</span>
            <span class="n">HColumnDescriptor</span> <span class="n">coldef</span> <span class="o">=</span> <span class="n">new</span> <span class="n">HColumnDescriptor</span><span class="p">(</span><span class="n">Bytes</span><span class="o">.</span><span class="n">toBytes</span><span class="p">(</span><span class="s2">&quot;colfamily&quot;</span><span class="p">));</span>
            <span class="n">desc</span><span class="o">.</span><span class="n">addFamily</span><span class="p">(</span><span class="n">coldef</span><span class="p">);</span>
            <span class="n">admin</span><span class="o">.</span><span class="n">createTable</span><span class="p">(</span><span class="n">desc</span><span class="p">);</span>
            <span class="n">Boolean</span> <span class="n">avail</span> <span class="o">=</span> <span class="n">admin</span><span class="o">.</span><span class="n">isTableAvailable</span><span class="p">(</span><span class="n">Bytes</span><span class="o">.</span><span class="n">toBytes</span><span class="p">(</span><span class="n">tablename</span><span class="p">));</span>
            <span class="n">System</span><span class="o">.</span><span class="n">out</span><span class="o">.</span><span class="n">println</span><span class="p">(</span><span class="s2">&quot;Table create: &quot;</span> <span class="o">+</span> <span class="n">avail</span><span class="p">);</span>
        <span class="p">}</span>
    <span class="err">}</span> <span class="nt">catch</span> <span class="o">(</span><span class="nt">IOException</span> <span class="nt">e</span><span class="o">)</span> <span class="p">{</span>
        <span class="o">//</span> <span class="n">TODO</span> <span class="n">Auto</span><span class="o">-</span><span class="n">generated</span> <span class="n">catch</span> <span class="k">block</span>
        <span class="n">e</span><span class="o">.</span><span class="n">printStackTrace</span><span class="p">();</span>
    <span class="p">}</span>
<span class="err">}</span>
</pre></div>


<p>分析：通过第一步，这一步就可以创建表，需要调用admin的建表函数createTable即可。当然要实例化一个表描述器desc和列族描述器coldef,并且向desc中添加coldef,然后admin.createTable(desc)即可建立表。</p>
<p>3 添加数据</p>
<div class="highlight"><pre>public static void addRow(String tablename){
    try {
        HTable table = new HTable(conf,tablename);
        Put put = new Put(Bytes.toBytes(&quot;row1&quot;));
        put.add(Bytes.toBytes(&quot;colfamily&quot;), Bytes.toBytes(&quot;col1&quot;), Bytes.toBytes(&quot;value1&quot;));
        put.add(Bytes.toBytes(&quot;colfamily&quot;), Bytes.toBytes(&quot;col2&quot;), Bytes.toBytes(&quot;value2&quot;));
        table.put(put);
    } catch (RetriesExhaustedWithDetailsException | InterruptedIOException e) {
        // TODO Auto-generated catch block
        e.printStackTrace();
    } catch (IOException e) {
        // TODO Auto-generated catch block
        e.printStackTrace();
    }
}
</pre></div>


<p>分析：这里有一个重要类HTable，可以用来和HBase表直接通信，比如向表中添加、删除、查看等操作，主要调用类HTable的成员函数即可，如put（添加数据），delete（删除数据）、get（获取指定行数据），getTableName获取表名，isTableEnabled检查表是否有有效等等。</p>
<p>这里用到了put(Put put)，则传入数据要实例化类Put。</p>
<p><strong>实验过程</strong></p>
<p>先把代码打成jar包（如hbase_api.jar），然后直接在利用命令<code>hadoop jar hbase_api.jar</code>执行即可:</p>
<p>先执行jar包：</p>
<blockquote>
<p><img alt="2" src="http://gitlab.local/course/course_hadoop/uploads/a19fac284f9b812d2a1f4d9e93998527/2.png" /></p>
</blockquote>
<p>查看建立的表和数据</p>
<blockquote>
<p><img alt="1" src="http://gitlab.local/course/course_hadoop/uploads/3693cb7303a57932ca1a6ccedf4f83a5/1.png" /></p>
</blockquote>
<p>发现表access_ysy已经建立，且加入两行数据。验证成功。</p>
<p></br>
二 <strong>用MapReduce完成hdfs数据向habse表的导入</strong></p>
<p>一中是通过api直接建立hbase表，并对表进行数据操作。但如果数据已经存在，如何导入，则显得尤为重要。这里将通过mapreduce，将hadoop中已经存在的数据文件的数据导入hbase表中。</p>
<p>主要通过map函数将数据读入，并输出到相同key值的reduce函数中，则遍历逐行的将每行的各个字段写入hbase表中即可。</p>
<p>整个代码比较简单，主要有三个类，建立表的类、map类和reduce类。因为hbase表不存在，则先建立一个表：</p>
<p>1 建表</p>
<div class="highlight"><pre>private static final String targetTable = &quot;mapreduce_yansiyu&quot;;
static Configuration config = HBaseConfiguration.create();
//创建表，表名为 targetTable，列族列表为cfs
public static void createTable(String tablename, String[] cfs) throws IOException {
    //建表
    HBaseAdmin admin = new HBaseAdmin(config);
    if (admin.tableExists(tablename)) {
        System.out.println(&quot;table already exists&quot;);
    }
    else {
        HTableDescriptor tableDesc = new HTableDescriptor(tablename);
        for (int i = 0; i &lt; cfs.length; i++) {
            //向表中加入列族
            tableDesc.addFamily(new HColumnDescriptor(cfs[i]));
        }
        //创建表
        admin.createTable(tableDesc);
        System.out.println(&quot;create table successly&quot;);
    }
}
</pre></div>


<p>2 map类</p>
<div class="highlight"><pre> public static class InputMapper extends Mapper&lt;Object, Text, NullWritable, Text&gt; {
    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
        //输出键值对的 键 为一样， 即空值。则map输出将进入同一个reduce中
        context.write(NullWritable.get(), value);
    }
}
</pre></div>


<p>可以看出读入的map中的数据，输出的键值对的键都相同，则都将进入同一个reduce中。</p>
<p>3 reduce类</p>
<div class="highlight"><pre>    public static class Reducer extends TableReducer&lt;NullWritable, Text, ImmutableBytesWritable&gt;{
    String time;
    String spName;
    String userID;
    String serverIP;
    String hostName;
    String uploadTraffic;
    String downloadTraffic;
    public void reduce(NullWritable key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException{
        //逐行将数据写入hbase表中
        for (Text val : values){
            String line = val.toString();
            String[] fields = line.split(&quot;\t&quot;);
            time = fields[0];
            userID = fields[1];
            serverIP = fields[2];
            hostName = fields[3];
            spName = fields[4];
            uploadTraffic = fields[5];
            downloadTraffic = fields[6];
            Put put = new Put(Bytes.toBytes(time));
            put.add(Bytes.toBytes(&quot;colfamily&quot;), Bytes.toBytes(&quot;userID&quot;), Bytes.toBytes(userID));
            put.add(Bytes.toBytes(&quot;colfamily&quot;), Bytes.toBytes(&quot;serverIP&quot;), Bytes.toBytes(serverIP));
            put.add(Bytes.toBytes(&quot;colfamily&quot;), Bytes.toBytes(&quot;hostName&quot;), Bytes.toBytes(hostName));
            put.add(Bytes.toBytes(&quot;colfamily&quot;), Bytes.toBytes(&quot;spName&quot;), Bytes.toBytes(spName));
            put.add(Bytes.toBytes(&quot;colfamily&quot;), Bytes.toBytes(&quot;uploadTraffic&quot;), Bytes.toBytes(uploadTraffic));
            put.add(Bytes.toBytes(&quot;colfamily&quot;), Bytes.toBytes(&quot;downloadTraffic&quot;), Bytes.toBytes(downloadTraffic));
            context.write(null, put);
        }
    }
}
</pre></div>


<p>整体思路很简单，values是一个数组，每个数据等效为一行数据，因此逐行遍历输出到habse表中即可。这里需要注意的是，hbase表输入数据必须通过对象put，因为需要把输出的值设置为put类型的对象。</p>
<p>当然，要正常运行，不同于平常的mapreduce的函数是，主函数中需要设置zookeeper,并且必须初始化habse表类型的的reduce类：</p>
<p>主函数，如下：</p>
<div class="highlight"><pre>    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {
    // TODO Auto-generated method stub
    String[] cfs = {&quot;colfamily&quot;};
    //配置zookeeper
    config.set(&quot;hbase.zookeeper.quorum&quot;, &quot;Master&quot;);
    //创建表
    createTable(targetTable, cfs);
    Job job = new Job(config, &quot;InputHBase&quot;);
    job.setJarByClass(hdfs2hbase.class);
    job.setMapperClass(InputMapper.class);

    TableMapReduceUtil.initTableReducerJob(
            targetTable,        
            Reducer.class,    
            job);
    FileInputFormat.addInputPath(job, new Path(args[0]));
    job.setOutputKeyClass(NullWritable.class);
    job.setOutputValueClass(Text.class);
    boolean b = job.waitForCompletion(true);
    if(!b){
        throw new IOException(&quot;error&quot;);
    }
}
</pre></div>


<p><strong>实验过程</strong></p>
<p>先把代码打成jar包（如Hbase_Input.jar），然后直接在利用命令hadoop jar Hbase_Input.jar /user/yansiyu/hbase/access.log`执行即可，但是注意执行时候后面要加上输入文件的位置:</p>
<p>先执行jar包：</p>
<blockquote>
<p><img alt="3" src="http://gitlab.local/course/course_hadoop/uploads/364bb8e4c35cc21778bd0f323ccbe41a/3.png" /></p>
</blockquote>
<p>查看建立的表和导入的数据</p>
<blockquote>
<p><img alt="4" src="http://gitlab.local/course/course_hadoop/uploads/78b6e43c161dd17a055a83a89af60114/4.png" /></p>
</blockquote>
<p>发现表mapreduce_yansiyu已经建立，并且与原来的access.log中数据进行对比，hbase表中数据导入成功。</p>
<h4><strong>结语</strong></h4>
<p>总体来说，hbase shell或是api操作还是比较简答的，但是究其原理较为复杂，理解它却更显重要。</p>
<p>通过这一学期学习---老师讲解与自己练习，从hadoop最基本的原理，mapreduce程序的书写，到hive、pig和hbase的学习与操作，让我对基于hadoop的大数据处理技术有了基本的了解，深知这也只是入门的皮毛而已。在今后的学习中，能够深入其本质，拓展更宽的知识，并能项目或工作结合起来，也许是进一步学习的目标吧。</p></div>
        <hr />
    </div>
		

 
        

 

    <div class='article'>
        <a href="http://ysywh.github.io/pages/2015/06/01/HBase & HBase shell.html"><h2>HBase & HBase shell</h2></a>
        <div class= "well small"> 2015-06-01

by <a class="url fn" href="http://ysywh.github.io/author/ysy.html">ysy</a>
 


 </div>
        <div class="summary"><p></br></p>
<h3><strong>前言</strong></h3>
<p>HBase源于Google的BigData，是面向列的、基于HDFS、高性能的分布式数据库系统。面向海量存储和互联网应用。</p>
<ul>
<li>
<p>面向列：解决稀疏问题，即众多的列，但并非每列都有数据，且经常只访问很少的列</p>
</li>
<li>
<p>基于HDFS：解决海量问题，即低成本可扩展地处理以十亿为单位的数据表</p>
</li>
<li>
<p>高性能：解决高速问题，即高吞吐量和高并发</p>
</li>
</ul>
<hr />
<h3><strong>一 Hbase 与 RRBMS对比</strong></h3>
<p>RDBMS是基于关系型数据库，而HBase基于列模式的映射数据库，是Nosql模式。Hbase表示为简单的键-值对，简化了关系型数据库。用处不同。</p>
<ul>
<li>
<p>数据类型：Hbase只有简单的字符串类型，即只保存字符串。关系型数据库数据类型很丰富。</p>
</li>
<li>
<p>数据操作：插入、查询、删除和清空等操作，不像关系型数据库表与表之间有关系，所以无表与表之间的关联操作，因为其实也不需要。</p>
</li>
<li>
<p>存储模式：Hbase基于列存储,则有些列字段值可以无，且不同列族存储的文件是分离的。</p>
</li>
</ul>
<p>除此之外，Hbase更新数据时候会保留一定数量的版本。</p>
<p></br></p>
<h3><strong>二 系统框架</strong></h3>
<p>构成：Client,Zookeeper，HMaster ...</p> <a class="btn btn-info xsmall" href="http://ysywh.github.io/pages/2015/06/01/HBase & HBase shell.html">read more</a></div>
    </div>	
				

 
        

 

    <div class='article'>
        <a href="http://ysywh.github.io/pages/2015/05/28/设计模式——相关计数pairs、stripes实现.html"><h2>设计模式——相关计数pairs、stripes实现</h2></a>
        <div class= "well small"> 2015-05-28

by <a class="url fn" href="http://ysywh.github.io/author/ysy.html">ysy</a>
 


 </div>
        <div class="summary"><h4><strong>前言</strong></h4>
<p><strong>设计模式</strong>对于以后写代码很重要，就像现成的模板一样，可以在解决具体问题时候套用。简单的设计模式有计数、分类、过滤出来、排序、去重计数和相关计数，还有相关计数。</p>
<p>这里主要对“相关计数”这种设计模式进行Mapreduce分析与实现。实现方法主要有两种，pairs和stripes。效率有很大不同，尤其数据量和维度增大时候，stripes的性能就体现的更突出。</p>
<p>这种设计模式实际应用很多，主要是同现矩阵的建立，比如词库的同现矩阵建立，即某场景下，统计出任意两个词语出现的次数（或者概率）；再比如在超市，会分析大量顾客的购买记录得出商品之间的关系，因为有时候顾客买了这个就会买两一个，因此要通过挖掘这种关系来决定商品的摆放位置。这项生活中的例子，都用到了相关计数这种设计模式，因此其在数据挖掘等领域有重要作用。</p>
<p></br>
<strong>实验目标</strong></p>
<div class="highlight"><pre>2,3,1,4,5,2,3
1,2,5,2
4,5
1,3,4,1 ...</pre></div> <a class="btn btn-info xsmall" href="http://ysywh.github.io/pages/2015/05/28/设计模式——相关计数pairs、stripes实现.html">read more</a></div>
    </div>	
				

 
        

 

    <div class='article'>
        <a href="http://ysywh.github.io/pages/2015/03/11/Docker搭建Hadoop集群环境和Wordcount实验.html"><h2>Docker搭建Hadoop集群环境和Wordcount实验</h2></a>
        <div class= "well small"> 2015-03-11

by <a class="url fn" href="http://ysywh.github.io/author/ysy.html">ysy</a>
 


 </div>
        <div class="summary"><p><br></p>
<p>利用docker搭建Hadoop环境，并且完成Mapreduce中Word count实验  </p>
<hr />
<h4>一：实验目标</h4>
<ul>
<li>
<p>学习docker基本命令</p>
</li>
<li>
<p>搭建只有一个master和两个slave的Hadoop集群环境</p>
</li>
<li>
<p>进行wordcount实验,理解mapreduce和hdfs等工作机制</p>
</li>
</ul>
<h4>二：docker基本命令</h4>
<p>docket是目前较为流行的虚拟化技术，可以方便轻松的在Linux中建立容器，达到虚拟化需求。</p>
<p>基本操作命令如下，更多参考<a href="!http://dockerpool.com/static/books/docker_practice/index.html">这里</a>。</p>
<ul>
<li>
<p>启动容器：<code>docker run 镜像名</code></p>
</li>
<li>
<p>暂停容器：<code>docker stop 容器名</code></p>
</li>
<li>
<p>重启开启容器：<code>docker start 容器名</code></p>
</li>
<li>
<p>进入容器：<code>docker attach 容器名</code></p>
</li>
</ul>
<h4>三：Hadoop集群环境搭建</h4>
<p>1 Hadoop集群分为一个master和两个slave，因此依次用docker开启相应容器,其中需要做端口映射：</p>
<p><img alt="1" src="http://gitlab.local/uploads/course/course_hadoop/955c4756f3/1.png" /></p>
<p><img alt="2" src="http://gitlab.local/uploads/course/course_hadoop/7ce0511f3b/2.png" /></p>
<p><img alt="3" src="http://gitlab.local/uploads/course/course_hadoop/3ef073ba31/3.png" /></p>
<p>2 利用命令编辑： <code>vi /etc/hosts</code>,加入master和两个slave的容器号和ip。之后需要 <strong>开启sshd服务</strong> ，使其生效：' service  sshd ...</p> <a class="btn btn-info xsmall" href="http://ysywh.github.io/pages/2015/03/11/Docker搭建Hadoop集群环境和Wordcount实验.html">read more</a></div>
    </div>	
				

 
        

 

    <div class='article'>
        <a href="http://ysywh.github.io/pages/2015/03/02/MapReduce之letter count.html"><h2>MapReduce之letter count</h2></a>
        <div class= "well small"> 2015-03-02

by <a class="url fn" href="http://ysywh.github.io/author/ysy.html">ysy</a>
 


 </div>
        <div class="summary"><p><br></p>
<p>本节在安装好的Eclipse环境中，尝试使用 MapReduce编程环境，运行letter count代码进行学习验证。letter count 实验就是对一段英文中出现的每个字母进行数量统计，比较基础的练习。</p>
<hr />
<p>1 创建新的工程lettercount,并且加载需要的Hadoop库：</p>
<p><img alt="1" src="http://gitlab.local/uploads/course/course_hadoop/bf8af6a841/1.png" /></p>
<p><img alt="2" src="http://gitlab.local/uploads/course/course_hadoop/3e50a19c6b/2.png" /></p>
<p><img alt="3" src="http://gitlab.local/uploads/course/course_hadoop/b465f66e7d/3.png" /></p>
<p>2 在网上寻找一个mapreduce的Wordcount代码文件，在map类中添加计算letter的代码，并且注释掉计算word的代码，加上对每个字母进行统计的代码，map输出键值对为（字母，one)，在reduce中进行合计，于统计word思路相同：</p>
<p><img alt="5" src="http://gitlab.local/uploads/course/course_hadoop/acaaa07b4e/5.png" /></p>
<p>3 运行前添加输入和输入文件，输入文件内容是一段英文，经过mapreduce运行计算后会把letter计算结果输出到输出文件中：</p>
<p><img alt="4" src="http://gitlab.localuploads/course/course_hadoop/84a81d19fc/4.png" /></p>
<p><img alt="6" src="http://gitlab.local/uploads/course/course_hadoop/9754fce9ef/6.png" /></p>
<p>4 通过export输出jar包，然后导入带有Hadoop的Linux系统中，进行实际运行计算：</p>
<p><img alt="7" src="http://gitlab.local/uploads/course/course_hadoop/a1c5c158d1/7.png" /></p>
<p>5 可以通过对比输入文件内容，比较计算的输出的结果，输出文件为两个：</p>
<p><img alt="8" src="http://gitlab.local/uploads/course/course_hadoop/f70bf9a61c/8.png" /></p> <a class="btn btn-info xsmall" href="http://ysywh.github.io/pages/2015/03/02/MapReduce之letter count.html">read more</a></div>
    </div>	
				
<div class="pagination">
<ul>
    <li class="prev disabled"><a href="#">&larr; Previous</a></li>

    <li class="active"><a href="http://ysywh.github.io/category/hadoop.html">1</a></li>

    <li class="next disabled"><a href="#">&rarr; Next</a></li>

</ul>
</div>
 
  
        </div>
        
        <div class="span3">

            <div class="well" style="padding: 8px 0; background-color: #FBFBFB;">
            <ul class="nav nav-list">
                <li class="nav-header"> 
                Site
                </li>
            
                <li><a href="http://ysywh.github.io/archives.html">Archives</a>
                <li><a href="http://ysywh.github.io/tags.html">Tags</a>



                <li><a href="http://ysywh.github.io/feeds/all.atom.xml" rel="alternate">Atom feed</a></li>
                <li><a href="http://ysywh.github.io/feeds/all.rss.xml" rel="alternate">RSS feed</a></li>

            </ul>
            </div>


            <div class="well" style="padding: 8px 0; background-color: #FBFBFB;">
            <ul class="nav nav-list">
                <li class="nav-header"> 
                Categories
                </li>
                
                <li><a href="http://ysywh.github.io/category/hadoop.html">Hadoop</a></li>
                <li><a href="http://ysywh.github.io/category/program.html">program</a></li>
                <li><a href="http://ysywh.github.io/category/sdn.html">SDN</a></li>
                   
            </ul>
            </div>


            <div class="well" style="padding: 8px 0; background-color: #FBFBFB;">
            <ul class="nav nav-list">
                <li class="nav-header"> 
                Links
                </li>
            
                <li><a href="http://www.sdnlab.com/">sdnlab</a></li>
                <li><a href="http://www.sdnap.com/">sdnap</a></li>
                <li><a href="http://www.muzixing.com/">muzixing</a></li>
            </ul>
            </div>


            <div class="social">
            <div class="well" style="padding: 8px 0; background-color: #FBFBFB;">
            <ul class="nav nav-list">
                <li class="nav-header"> 
                Social
                </li>
           
                <li><a href="https://github.com/ysywh/">my github</a></li>
            </ul>
            </div>
            </div>

        </div>  
    </div>     </div> 
<footer>
<br />
<p><a href="http://ysywh.github.io">YsY记录点滴</a> &copy; yansy 2015</p>
</footer>

</div> <!-- /container -->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
<script src="http://ysywh.github.io/theme/bootstrap-collapse.js"></script>
<script>var _gaq=[['_setAccount','UA-62970575-1'],['_trackPageview']];(function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];g.src='//www.google-analytics.com/ga.js';s.parentNode.insertBefore(g,s)}(document,'script'))</script>
<a href="https://github.com/ysywh"><img style="position: absolute; top: 40px; right: 0; border: 0;" src="http://s3.amazonaws.com/github/ribbons/forkme_right_white_ffffff.png" alt="Fork me on GitHub" /></a>
 
</body>
</html>